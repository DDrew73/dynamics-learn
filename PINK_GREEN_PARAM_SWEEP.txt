

---begin--------------------------------------------------------------
Simulation update step is:  0.0002  and control update is:  0.004 the ratio is:  20.0
...Initializing Dynamics Object
var:	 CURRENT STATE
X: 	 0.0
Y: 	 0.0
Z: 	 0.0
vx: 	 0.0
vy: 	 0.0
vz: 	 0.0
yaw: 	 0.0
pitch: 	 0.0
roll: 	 0.0
wx: 	 22169.09523610705
wy: 	 25700.931067596342
wz: 	 248035.36649457447

...Generating Training Data
Original data:  (64891, 8)
Linear:  [6.42253311e+08 6.42253311e+08 6.41204735e+08 ... 7.04187902e+08
 6.63264780e+08 5.95057150e+08]
Angular:  [5.36346111e+08 5.36346111e+08 5.37394687e+08 ... 6.67941607e+08
 6.73184443e+08 6.58175620e+08]
[44797.53827187 42010.25054322 48112.41694534 41729.8462961 ]
added padding dimension to Seqs_X
added padding dimension to Seqs_U
Data : 
 [[[-1.40845070e-01 -1.40845070e-01 -1.40845070e-01  1.50557712e-01
   -1.57083923e+02]
  [-1.40845070e-01 -1.40845070e-01 -1.40845070e-01  1.50422066e-01
   -1.57083374e+02]
  [-1.40845070e-01 -1.40845070e-01  5.63380282e-01  1.49598628e-01
   -1.57080750e+02]
  ...
  [ 1.63239437e+02  3.59718310e+02  8.78873239e+01  5.74315720e+01
   -1.18355759e+02]
  [ 1.32253521e+02  3.59718310e+02  9.14084507e+01  5.74315720e+01
   -1.18355759e+02]
  [ 9.35211268e+01  1.33661972e+02  8.15492958e+01  5.25039978e+01
   -1.12094933e+02]]] [[[16384. 22016. 22272. 16640.]
  [17920. 20480. 20736. 17920.]
  [20224. 22272. 22784. 20224.]
  ...
  [65280.     0. 28416.     0.]
  [65280.     0. 28416.     0.]
  [60928. 28160. 60928.     0.]]]
.... loading training data
(1, 64890, 5)
(1, 64891, 5)
(1, 64891, 4)
das shape:  (64890, 3)
(1, 64890, 3)
(64890, 3)


---begin--------------------------------------------------------------
Simulation update step is:  0.0002  and control update is:  0.004 the ratio is:  20.0
...Initializing Dynamics Object
var:	 CURRENT STATE
X: 	 0.0
Y: 	 0.0
Z: 	 0.0
vx: 	 0.0
vy: 	 0.0
vz: 	 0.0
yaw: 	 0.0
pitch: 	 0.0
roll: 	 0.0
wx: 	 22169.09523610705
wy: 	 25700.931067596342
wz: 	 248035.36649457447

...Generating Training Data
Original data:  (91336, 8)
Linear:  [6.41203712e+08 6.41203712e+08 6.41203712e+08 ... 6.34912261e+08
 6.37008388e+08 6.37006341e+08]
Angular:  [5.36346111e+08 5.36346111e+08 5.36346111e+08 ... 5.33208546e+08
 5.32157924e+08 5.31104231e+08]
[44394.9675046  43043.28492599 43285.08014365 38946.7972322 ]
added padding dimension to Seqs_X
added padding dimension to Seqs_U
Data : 
 [[[-1.40845070e-01 -1.40845070e-01 -1.40845070e-01 -2.87373245e-01
    1.50312927e+02]
  [-1.40845070e-01 -1.40845070e-01 -1.40845070e-01 -2.87562102e-01
    1.50313446e+02]
  [-1.40845070e-01 -1.40845070e-01 -1.40845070e-01 -2.87575841e-01
    1.50313995e+02]
  ...
  [-2.05633803e+01  5.49295775e+00 -2.25352113e+00 -9.41088915e-01
    1.75972885e+02]
  [-1.91549296e+01  4.08450704e+00 -2.95774648e+00 -1.01938200e+00
    1.75962524e+02]
  [-1.70422535e+01  5.63380282e-01 -3.66197183e+00 -1.09224117e+00
    1.75950699e+02]]] [[[19200. 22784. 23552. 19968.]
  [25088. 28928. 29696. 25856.]
  [25088. 28928. 29696. 25856.]
  ...
  [65280. 34560. 38400. 40192.]
  [65280. 35072. 38144. 39936.]
  [65280. 35328. 38144. 39680.]]]
.... loading training data
(1, 91335, 5)
(1, 91336, 5)
(1, 91336, 4)
das shape:  (91335, 3)
(1, 91335, 3)
(91335, 3)
------------------------------Running Depth= 1 	Width= 50 ------------------------------
Epoch: 0001 train loss= 17071.117188 test loss= 2960.491454
Epoch: 0002 train loss= 16915.738281 test loss= 2637.940298
Saved:  _models/sweep/w-50_d-1_e-2_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 16761.789062 test loss= 2360.033586
Epoch: 0002 train loss= 16611.267578 test loss= 2130.145553
Saved:  _models/sweep/w-50_d-1_e-4_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 16463.333984 test loss= 1933.409418
Epoch: 0002 train loss= 16317.761719 test loss= 1768.826162
Saved:  _models/sweep/w-50_d-1_e-6_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 16172.267578 test loss= 1625.181921
Epoch: 0002 train loss= 16029.632812 test loss= 1505.005372
Saved:  _models/sweep/w-50_d-1_e-8_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 15888.500000 test loss= 1401.600697
Epoch: 0002 train loss= 15750.141602 test loss= 1313.712414
Saved:  _models/sweep/w-50_d-1_e-10_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 15614.309570 test loss= 1237.073469
Epoch: 0002 train loss= 15479.097656 test loss= 1170.634139
Saved:  _models/sweep/w-50_d-1_e-12_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 15344.860352 test loss= 1112.064035
Epoch: 0002 train loss= 15213.266602 test loss= 1062.060766
Saved:  _models/sweep/w-50_d-1_e-14_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 15081.782227 test loss= 1016.698500
Epoch: 0002 train loss= 14953.642578 test loss= 978.208863
Saved:  _models/sweep/w-50_d-1_e-16_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 14825.890625 test loss= 943.231401
Epoch: 0002 train loss= 14700.164062 test loss= 912.451845
Saved:  _models/sweep/w-50_d-1_e-18_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 14575.003906 test loss= 884.267566
Epoch: 0002 train loss= 14451.557617 test loss= 859.238084
Saved:  _models/sweep/w-50_d-1_e-20_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 14329.422852 test loss= 836.198252
Epoch: 0002 train loss= 14208.752930 test loss= 815.470674
Saved:  _models/sweep/w-50_d-1_e-22_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 14088.820312 test loss= 796.218335
Epoch: 0002 train loss= 13969.651367 test loss= 778.602808
Saved:  _models/sweep/w-50_d-1_e-24_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 13850.478516 test loss= 762.017742
Epoch: 0002 train loss= 13733.277344 test loss= 746.859350
Saved:  _models/sweep/w-50_d-1_e-26_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 13616.442383 test loss= 732.612093
Epoch: 0002 train loss= 13501.347656 test loss= 719.347546
Saved:  _models/sweep/w-50_d-1_e-28_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 13386.257812 test loss= 706.574833
Epoch: 0002 train loss= 13272.151367 test loss= 694.623137
Saved:  _models/sweep/w-50_d-1_e-30_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 13157.857422 test loss= 682.974640
Epoch: 0002 train loss= 13044.866211 test loss= 672.022542
Saved:  _models/sweep/w-50_d-1_e-32_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 12932.655273 test loss= 661.621108
Epoch: 0002 train loss= 12821.425781 test loss= 651.606725
Saved:  _models/sweep/w-50_d-1_e-34_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 12710.195312 test loss= 641.890919
Epoch: 0002 train loss= 12600.497070 test loss= 632.682240
Saved:  _models/sweep/w-50_d-1_e-36_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 12491.632812 test loss= 623.798347
Epoch: 0002 train loss= 12382.995117 test loss= 615.232782
Saved:  _models/sweep/w-50_d-1_e-38_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 12275.080078 test loss= 606.956350
Epoch: 0002 train loss= 12168.032227 test loss= 598.908913
Saved:  _models/sweep/w-50_d-1_e-40_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 12059.228516 test loss= 590.877351
Epoch: 0002 train loss= 11951.896484 test loss= 583.233307
Saved:  _models/sweep/w-50_d-1_e-42_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 11846.147461 test loss= 575.801660
Epoch: 0002 train loss= 11740.142578 test loss= 568.511473
Saved:  _models/sweep/w-50_d-1_e-44_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 11633.655273 test loss= 561.326751
Epoch: 0002 train loss= 11528.974609 test loss= 554.435055
Saved:  _models/sweep/w-50_d-1_e-46_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 11423.959961 test loss= 547.548494
Epoch: 0002 train loss= 11319.237305 test loss= 540.791071
Saved:  _models/sweep/w-50_d-1_e-48_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 11215.387695 test loss= 534.230813
Epoch: 0002 train loss= 11111.700195 test loss= 527.777060
Saved:  _models/sweep/w-50_d-1_e-50_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 11007.137695 test loss= 521.348118
Epoch: 0002 train loss= 10903.458984 test loss= 515.113342
Saved:  _models/sweep/w-50_d-1_e-52_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 10800.899414 test loss= 508.968505
Epoch: 0002 train loss= 10698.309570 test loss= 502.933588
Saved:  _models/sweep/w-50_d-1_e-54_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 10595.320312 test loss= 496.891164
Epoch: 0002 train loss= 10493.297852 test loss= 491.057793
Saved:  _models/sweep/w-50_d-1_e-56_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 10392.149414 test loss= 485.302711
Epoch: 0002 train loss= 10290.832031 test loss= 479.589222
Saved:  _models/sweep/w-50_d-1_e-58_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 10189.045898 test loss= 473.877664
Epoch: 0002 train loss= 10087.833008 test loss= 468.308235
Saved:  _models/sweep/w-50_d-1_e-60_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 9985.687500 test loss= 462.704958
Epoch: 0002 train loss= 9884.701172 test loss= 457.271825
Saved:  _models/sweep/w-50_d-1_e-62_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 9784.373047 test loss= 451.884908
Epoch: 0002 train loss= 9684.594727 test loss= 446.555685
Saved:  _models/sweep/w-50_d-1_e-64_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 9584.448242 test loss= 441.264757
Epoch: 0002 train loss= 9485.192383 test loss= 436.044244
Saved:  _models/sweep/w-50_d-1_e-66_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 9385.559570 test loss= 430.871022
Epoch: 0002 train loss= 9286.534180 test loss= 425.770064
Saved:  _models/sweep/w-50_d-1_e-68_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 9187.412109 test loss= 420.651343
Epoch: 0002 train loss= 9088.680664 test loss= 415.644742
Saved:  _models/sweep/w-50_d-1_e-70_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 8990.379883 test loss= 410.667076
Epoch: 0002 train loss= 8892.450195 test loss= 405.751128
Saved:  _models/sweep/w-50_d-1_e-72_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 8795.084961 test loss= 400.890141
Epoch: 0002 train loss= 8697.973633 test loss= 396.040285
Saved:  _models/sweep/w-50_d-1_e-74_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 8601.488281 test loss= 391.243252
Epoch: 0002 train loss= 8504.986328 test loss= 386.469955
Saved:  _models/sweep/w-50_d-1_e-76_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 8408.294922 test loss= 381.748207
Epoch: 0002 train loss= 8312.236328 test loss= 377.060966
Saved:  _models/sweep/w-50_d-1_e-78_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 8216.055664 test loss= 372.364739
Epoch: 0002 train loss= 8120.920898 test loss= 367.766826
Saved:  _models/sweep/w-50_d-1_e-80_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 8026.141113 test loss= 363.211318
Epoch: 0002 train loss= 7932.222656 test loss= 358.737049
Saved:  _models/sweep/w-50_d-1_e-82_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 7838.350098 test loss= 354.265647
Epoch: 0002 train loss= 7745.511719 test loss= 349.881304
Saved:  _models/sweep/w-50_d-1_e-84_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 7653.253418 test loss= 345.504705
Epoch: 0002 train loss= 7561.613770 test loss= 341.181291
Saved:  _models/sweep/w-50_d-1_e-86_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 7470.731445 test loss= 336.959141
Epoch: 0002 train loss= 7380.321289 test loss= 332.725537
Saved:  _models/sweep/w-50_d-1_e-88_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 7290.080078 test loss= 328.545829
Epoch: 0002 train loss= 7200.631836 test loss= 324.389824
Saved:  _models/sweep/w-50_d-1_e-90_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 7111.805176 test loss= 320.256483
Epoch: 0002 train loss= 7023.893066 test loss= 316.220957
Saved:  _models/sweep/w-50_d-1_e-92_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 6936.745117 test loss= 312.238584
Epoch: 0002 train loss= 6850.366211 test loss= 308.315177
Saved:  _models/sweep/w-50_d-1_e-94_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 6764.649902 test loss= 304.404359
Epoch: 0002 train loss= 6680.021484 test loss= 300.560071
Saved:  _models/sweep/w-50_d-1_e-96_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 6595.709473 test loss= 296.755622
Epoch: 0002 train loss= 6512.482910 test loss= 293.021874
Saved:  _models/sweep/w-50_d-1_e-98_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 6429.974609 test loss= 289.307135
Epoch: 0002 train loss= 6348.364746 test loss= 285.690803
Saved:  _models/sweep/w-50_d-1_e-100_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 6267.851074 test loss= 282.144599
Epoch: 0002 train loss= 6188.085938 test loss= 278.612865
Saved:  _models/sweep/w-50_d-1_e-102_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 6109.293945 test loss= 275.201327
Epoch: 0002 train loss= 6031.467285 test loss= 271.788493
Saved:  _models/sweep/w-50_d-1_e-104_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 5954.023438 test loss= 268.462898
Epoch: 0002 train loss= 5878.130371 test loss= 265.124497
Saved:  _models/sweep/w-50_d-1_e-106_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 5801.997559 test loss= 261.773603
Epoch: 0002 train loss= 5728.004395 test loss= 258.585215
Saved:  _models/sweep/w-50_d-1_e-108_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 5655.043457 test loss= 255.378285
Epoch: 0002 train loss= 5582.966309 test loss= 252.282842
Saved:  _models/sweep/w-50_d-1_e-110_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 5511.560059 test loss= 249.249817
Epoch: 0002 train loss= 5441.704102 test loss= 246.250184
Saved:  _models/sweep/w-50_d-1_e-112_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 5373.306152 test loss= 243.366977
Epoch: 0002 train loss= 5305.791504 test loss= inf
------------------------------Completed Depth=1	Width= 50 !------------------------------
------------------------------Running Depth= 2 	Width= 50 ------------------------------
Epoch: 0001 train loss= 15483.733398 test loss= 1551.778589
Epoch: 0002 train loss= 15398.777344 test loss= 1509.409996
Saved:  _models/sweep/w-50_d-2_e-2_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 15313.144531 test loss= 1468.692462
Epoch: 0002 train loss= 15229.114258 test loss= 1429.897859
Saved:  _models/sweep/w-50_d-2_e-4_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 15145.181641 test loss= 1392.477213
Epoch: 0002 train loss= 15061.833008 test loss= 1358.245185
Saved:  _models/sweep/w-50_d-2_e-6_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 14978.664062 test loss= 1325.548447
Epoch: 0002 train loss= 14895.554688 test loss= 1293.055803
Saved:  _models/sweep/w-50_d-2_e-8_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 14811.855469 test loss= 1260.321850
Epoch: 0002 train loss= 14729.153320 test loss= 1230.189143
Saved:  _models/sweep/w-50_d-2_e-10_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 14646.264648 test loss= 1200.311190
Epoch: 0002 train loss= 14563.858398 test loss= 1171.037227
Saved:  _models/sweep/w-50_d-2_e-12_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 14481.039062 test loss= 1143.032026
Epoch: 0002 train loss= 14398.388672 test loss= 1115.543633
Saved:  _models/sweep/w-50_d-2_e-14_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 14315.302734 test loss= 1088.602320
Epoch: 0002 train loss= 14232.203125 test loss= 1062.379365
Saved:  _models/sweep/w-50_d-2_e-16_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 14149.041992 test loss= 1036.208007
Epoch: 0002 train loss= 14065.461914 test loss= 1011.084697
Saved:  _models/sweep/w-50_d-2_e-18_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 13981.112305 test loss= 985.998532
Epoch: 0002 train loss= 13896.682617 test loss= 961.803189
Saved:  _models/sweep/w-50_d-2_e-20_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 13812.178711 test loss= 938.519839
Epoch: 0002 train loss= 13726.575195 test loss= 915.127730
Saved:  _models/sweep/w-50_d-2_e-22_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 13639.916992 test loss= 892.634042
Epoch: 0002 train loss= 13552.911133 test loss= 870.536334
Saved:  _models/sweep/w-50_d-2_e-24_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 13464.862305 test loss= 849.556009
Epoch: 0002 train loss= 13376.193359 test loss= 828.379430
Saved:  _models/sweep/w-50_d-2_e-26_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 13285.952148 test loss= 807.522380
Epoch: 0002 train loss= 13195.149414 test loss= 786.516682
Saved:  _models/sweep/w-50_d-2_e-28_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 13103.249023 test loss= 766.262971
Epoch: 0002 train loss= 13010.747070 test loss= 746.071943
Saved:  _models/sweep/w-50_d-2_e-30_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 12916.916016 test loss= 726.341565
Epoch: 0002 train loss= 12821.804688 test loss= 707.086893
Saved:  _models/sweep/w-50_d-2_e-32_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 12724.982422 test loss= 688.268394
Epoch: 0002 train loss= 12628.306641 test loss= 669.986124
Saved:  _models/sweep/w-50_d-2_e-34_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 12529.714844 test loss= 651.568083
Epoch: 0002 train loss= 12430.873047 test loss= 633.820972
Saved:  _models/sweep/w-50_d-2_e-36_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 12330.664062 test loss= 616.813492
Epoch: 0002 train loss= 12229.666992 test loss= 600.177849
Saved:  _models/sweep/w-50_d-2_e-38_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 12127.428711 test loss= 584.060741
Epoch: 0002 train loss= 12024.375977 test loss= 568.853121
Saved:  _models/sweep/w-50_d-2_e-40_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 11919.764648 test loss= 554.354428
Epoch: 0002 train loss= 11814.808594 test loss= 540.479655
Saved:  _models/sweep/w-50_d-2_e-42_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 11708.655273 test loss= 527.452581
Epoch: 0002 train loss= 11601.675781 test loss= 514.781318
Saved:  _models/sweep/w-50_d-2_e-44_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 11493.251953 test loss= 502.600099
Epoch: 0002 train loss= 11384.128906 test loss= 490.996755
Saved:  _models/sweep/w-50_d-2_e-46_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 11274.339844 test loss= 479.819472
Epoch: 0002 train loss= 11163.875000 test loss= 469.172703
Saved:  _models/sweep/w-50_d-2_e-48_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 11052.727539 test loss= 459.051047
Epoch: 0002 train loss= 10939.973633 test loss= 448.937327
Saved:  _models/sweep/w-50_d-2_e-50_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 10826.056641 test loss= 439.217391
Epoch: 0002 train loss= 10712.182617 test loss= 429.809413
Saved:  _models/sweep/w-50_d-2_e-52_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 10597.975586 test loss= 420.891577
Epoch: 0002 train loss= 10482.806641 test loss= 412.111623
Saved:  _models/sweep/w-50_d-2_e-54_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 10364.619141 test loss= 403.397467
Epoch: 0002 train loss= 10247.135742 test loss= 395.210579
Saved:  _models/sweep/w-50_d-2_e-56_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 10128.600586 test loss= 387.139625
Epoch: 0002 train loss= 10010.966797 test loss= 379.493251
Saved:  _models/sweep/w-50_d-2_e-58_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 9892.664062 test loss= 372.025131
Epoch: 0002 train loss= 9773.662109 test loss= 364.754485
Saved:  _models/sweep/w-50_d-2_e-60_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 9654.388672 test loss= 357.692736
Epoch: 0002 train loss= 9535.464844 test loss= 350.894478
Saved:  _models/sweep/w-50_d-2_e-62_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 9416.038086 test loss= 344.246822
Epoch: 0002 train loss= 9296.338867 test loss= 337.767597
Saved:  _models/sweep/w-50_d-2_e-64_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 9177.035156 test loss= 331.523877
Epoch: 0002 train loss= 9056.826172 test loss= 325.377783
Saved:  _models/sweep/w-50_d-2_e-66_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 8936.500977 test loss= 319.380193
Epoch: 0002 train loss= 8816.329102 test loss= 313.568915
Saved:  _models/sweep/w-50_d-2_e-68_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 8697.466797 test loss= 307.957613
Epoch: 0002 train loss= 8577.816406 test loss= 302.380492
Saved:  _models/sweep/w-50_d-2_e-70_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 8458.484375 test loss= 296.943549
Epoch: 0002 train loss= 8339.060547 test loss= 291.661963
Saved:  _models/sweep/w-50_d-2_e-72_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 8219.159180 test loss= 286.440927
Epoch: 0002 train loss= 8100.467285 test loss= 281.403012
Saved:  _models/sweep/w-50_d-2_e-74_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 7982.490234 test loss= 276.502677
Epoch: 0002 train loss= 7865.297852 test loss= 271.729083
Saved:  _models/sweep/w-50_d-2_e-76_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 7747.897949 test loss= 266.987003
Epoch: 0002 train loss= 7632.050781 test loss= 262.479579
Saved:  _models/sweep/w-50_d-2_e-78_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 7516.254883 test loss= 258.013611
Epoch: 0002 train loss= 7401.861328 test loss= 253.718901
Saved:  _models/sweep/w-50_d-2_e-80_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 7288.666504 test loss= 249.518868
Epoch: 0002 train loss= 7176.556152 test loss= 245.443059
Saved:  _models/sweep/w-50_d-2_e-82_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 7066.396484 test loss= 241.501500
Epoch: 0002 train loss= 6956.865723 test loss= 237.646719
Saved:  _models/sweep/w-50_d-2_e-84_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 6848.826660 test loss= 233.927908
Epoch: 0002 train loss= 6741.837402 test loss= 230.291701
Saved:  _models/sweep/w-50_d-2_e-86_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 6636.147461 test loss= 226.767068
Epoch: 0002 train loss= 6532.001465 test loss= 223.353713
Saved:  _models/sweep/w-50_d-2_e-88_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 6429.559570 test loss= 220.034323
Epoch: 0002 train loss= 6329.012695 test loss= 216.839973
Saved:  _models/sweep/w-50_d-2_e-90_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 6229.833008 test loss= 213.702681
Epoch: 0002 train loss= 6132.747559 test loss= 210.717003
Saved:  _models/sweep/w-50_d-2_e-92_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 6036.376465 test loss= 207.761494
Epoch: 0002 train loss= 5943.080566 test loss= 205.009535
Saved:  _models/sweep/w-50_d-2_e-94_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 5851.850586 test loss= 202.313365
Epoch: 0002 train loss= 5763.024902 test loss= 199.747129
Saved:  _models/sweep/w-50_d-2_e-96_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 5676.603027 test loss= 197.300552
Epoch: 0002 train loss= 5592.126953 test loss= 194.969776
Saved:  _models/sweep/w-50_d-2_e-98_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 5509.236328 test loss= 192.688207
Epoch: 0002 train loss= 5429.353516 test loss= 190.576107
Saved:  _models/sweep/w-50_d-2_e-100_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 5351.414062 test loss= 188.536392
Epoch: 0002 train loss= 5276.293945 test loss= inf
------------------------------Completed Depth=2	Width= 50 !------------------------------
------------------------------Running Depth= 3 	Width= 50 ------------------------------
Epoch: 0001 train loss= 15711.970703 test loss= 1223.975155
Epoch: 0002 train loss= 15652.595703 test loss= 1212.154055
Saved:  _models/sweep/w-50_d-3_e-2_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 15593.720703 test loss= 1200.525710
Epoch: 0002 train loss= 15535.326172 test loss= 1189.104520
Saved:  _models/sweep/w-50_d-3_e-4_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 15477.152344 test loss= 1177.396598
Epoch: 0002 train loss= 15419.637695 test loss= 1166.362410
Saved:  _models/sweep/w-50_d-3_e-6_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 15362.483398 test loss= 1155.899468
Epoch: 0002 train loss= 15305.884766 test loss= 1144.875122
Saved:  _models/sweep/w-50_d-3_e-8_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 15249.250977 test loss= 1133.440399
Epoch: 0002 train loss= 15192.660156 test loss= 1121.648529
Saved:  _models/sweep/w-50_d-3_e-10_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 15136.070312 test loss= 1109.799558
Epoch: 0002 train loss= 15079.761719 test loss= 1098.199659
Saved:  _models/sweep/w-50_d-3_e-12_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 15022.836914 test loss= 1086.051296
Epoch: 0002 train loss= 14966.114258 test loss= 1074.591541
Saved:  _models/sweep/w-50_d-3_e-14_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 14908.664062 test loss= 1062.540002
Epoch: 0002 train loss= 14850.917969 test loss= 1050.620813
Saved:  _models/sweep/w-50_d-3_e-16_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 14791.849609 test loss= 1038.278352
Epoch: 0002 train loss= 14732.699219 test loss= 1026.004611
Saved:  _models/sweep/w-50_d-3_e-18_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 14672.396484 test loss= 1013.464245
Epoch: 0002 train loss= 14611.805664 test loss= 1000.807869
Saved:  _models/sweep/w-50_d-3_e-20_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 14550.169922 test loss= 987.798193
Epoch: 0002 train loss= 14487.479492 test loss= 974.582063
Saved:  _models/sweep/w-50_d-3_e-22_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 14423.471680 test loss= 960.273472
Epoch: 0002 train loss= 14358.282227 test loss= 946.319181
Saved:  _models/sweep/w-50_d-3_e-24_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 14291.174805 test loss= 932.238961
Epoch: 0002 train loss= 14223.634766 test loss= 918.233539
Saved:  _models/sweep/w-50_d-3_e-26_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 14153.835938 test loss= 903.903772
Epoch: 0002 train loss= 14083.100586 test loss= 889.967302
Saved:  _models/sweep/w-50_d-3_e-28_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 14010.583984 test loss= 875.952462
Epoch: 0002 train loss= 13936.944336 test loss= 862.133854
Saved:  _models/sweep/w-50_d-3_e-30_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 13860.570312 test loss= 848.511244
Epoch: 0002 train loss= 13782.852539 test loss= 834.576204
Saved:  _models/sweep/w-50_d-3_e-32_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 13703.444336 test loss= 820.769761
Epoch: 0002 train loss= 13622.793945 test loss= 806.666105
Saved:  _models/sweep/w-50_d-3_e-34_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 13539.004883 test loss= 792.505809
Epoch: 0002 train loss= 13454.078125 test loss= 778.393538
Saved:  _models/sweep/w-50_d-3_e-36_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 13366.561523 test loss= 763.785885
Epoch: 0002 train loss= 13277.345703 test loss= 749.425618
Saved:  _models/sweep/w-50_d-3_e-38_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 13187.278320 test loss= 735.341867
Epoch: 0002 train loss= 13094.475586 test loss= 721.098733
Saved:  _models/sweep/w-50_d-3_e-40_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 12998.937500 test loss= 707.120646
Epoch: 0002 train loss= 12901.433594 test loss= 693.179479
Saved:  _models/sweep/w-50_d-3_e-42_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 12801.745117 test loss= 679.546506
Epoch: 0002 train loss= 12699.505859 test loss= 665.870392
Saved:  _models/sweep/w-50_d-3_e-44_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 12594.944336 test loss= 652.496938
Epoch: 0002 train loss= 12487.820312 test loss= 639.183289
Saved:  _models/sweep/w-50_d-3_e-46_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 12377.740234 test loss= 626.043032
Epoch: 0002 train loss= 12265.188477 test loss= 613.171699
Saved:  _models/sweep/w-50_d-3_e-48_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 12149.617188 test loss= 600.442355
Epoch: 0002 train loss= 12031.965820 test loss= 588.013494
Saved:  _models/sweep/w-50_d-3_e-50_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 11912.001953 test loss= 576.077107
Epoch: 0002 train loss= 11789.899414 test loss= 564.194181
Saved:  _models/sweep/w-50_d-3_e-52_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 11665.546875 test loss= 552.724072
Epoch: 0002 train loss= 11538.372070 test loss= 541.448016
Saved:  _models/sweep/w-50_d-3_e-54_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 11409.729492 test loss= 530.717355
Epoch: 0002 train loss= 11278.752930 test loss= 520.006374
Saved:  _models/sweep/w-50_d-3_e-56_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 11145.381836 test loss= 509.672946
Epoch: 0002 train loss= 11010.357422 test loss= 499.548608
Saved:  _models/sweep/w-50_d-3_e-58_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 10872.749023 test loss= 489.650449
Epoch: 0002 train loss= 10733.618164 test loss= 479.953174
Saved:  _models/sweep/w-50_d-3_e-60_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 10590.452148 test loss= 470.305116
Epoch: 0002 train loss= 10447.365234 test loss= 460.995497
Saved:  _models/sweep/w-50_d-3_e-62_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 10302.847656 test loss= 451.880365
Epoch: 0002 train loss= 10156.474609 test loss= 442.920890
Saved:  _models/sweep/w-50_d-3_e-64_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 10007.747070 test loss= 434.129204
Epoch: 0002 train loss= 9858.641602 test loss= 425.536303
Saved:  _models/sweep/w-50_d-3_e-66_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 9707.083984 test loss= 417.021201
Epoch: 0002 train loss= 9555.384766 test loss= 408.718722
Saved:  _models/sweep/w-50_d-3_e-68_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 9401.802734 test loss= 400.565987
Epoch: 0002 train loss= 9247.584961 test loss= 392.540333
Saved:  _models/sweep/w-50_d-3_e-70_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 9092.201172 test loss= 384.580620
Epoch: 0002 train loss= 8936.846680 test loss= 376.812117
Saved:  _models/sweep/w-50_d-3_e-72_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 8779.433594 test loss= 369.136703
Epoch: 0002 train loss= 8623.334961 test loss= 361.581749
Saved:  _models/sweep/w-50_d-3_e-74_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 8466.064453 test loss= 354.056870
Epoch: 0002 train loss= 8310.448242 test loss= 346.783726
Saved:  _models/sweep/w-50_d-3_e-76_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 8155.226074 test loss= 339.555286
Epoch: 0002 train loss= 8001.062988 test loss= 332.463212
Saved:  _models/sweep/w-50_d-3_e-78_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 7848.661621 test loss= 325.477494
Epoch: 0002 train loss= 7697.007812 test loss= 318.684024
Saved:  _models/sweep/w-50_d-3_e-80_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 7546.236328 test loss= 312.011564
Epoch: 0002 train loss= 7398.681641 test loss= 305.597342
Saved:  _models/sweep/w-50_d-3_e-82_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 7252.580078 test loss= 299.297602
Epoch: 0002 train loss= 7109.625000 test loss= 293.180816
Saved:  _models/sweep/w-50_d-3_e-84_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 6969.710449 test loss= 287.285244
Epoch: 0002 train loss= 6831.825195 test loss= 281.494489
Saved:  _models/sweep/w-50_d-3_e-86_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 6698.147949 test loss= 276.001275
Epoch: 0002 train loss= 6566.869141 test loss= 270.605563
Saved:  _models/sweep/w-50_d-3_e-88_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 6439.052246 test loss= 265.364466
Epoch: 0002 train loss= 6315.325684 test loss= inf
------------------------------Completed Depth=3	Width= 50 !------------------------------
------------------------------Running Depth= 4 	Width= 50 ------------------------------
Epoch: 0001 train loss= 15643.029297 test loss= 1445.616534
Epoch: 0002 train loss= 15598.831055 test loss= 1436.748297
Saved:  _models/sweep/w-50_d-4_e-2_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 15554.233398 test loss= 1427.551052
Epoch: 0002 train loss= 15509.424805 test loss= 1418.469023
Saved:  _models/sweep/w-50_d-4_e-4_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 15464.284180 test loss= 1409.525818
Epoch: 0002 train loss= 15418.868164 test loss= 1400.230810
Saved:  _models/sweep/w-50_d-4_e-6_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 15372.988281 test loss= 1391.226789
Epoch: 0002 train loss= 15326.647461 test loss= 1381.954720
Saved:  _models/sweep/w-50_d-4_e-8_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 15279.708008 test loss= 1372.179758
Epoch: 0002 train loss= 15232.709961 test loss= 1361.697490
Saved:  _models/sweep/w-50_d-4_e-10_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 15184.576172 test loss= 1350.934801
Epoch: 0002 train loss= 15136.312500 test loss= 1339.584166
Saved:  _models/sweep/w-50_d-4_e-12_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 15087.337891 test loss= 1328.274190
Epoch: 0002 train loss= 15038.018555 test loss= 1316.309907
Saved:  _models/sweep/w-50_d-4_e-14_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 14987.639648 test loss= 1303.699231
Epoch: 0002 train loss= 14937.160156 test loss= 1290.553282
Saved:  _models/sweep/w-50_d-4_e-16_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 14885.553711 test loss= 1276.939021
Epoch: 0002 train loss= 14833.590820 test loss= 1263.237479
Saved:  _models/sweep/w-50_d-4_e-18_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 14780.788086 test loss= 1249.455828
Epoch: 0002 train loss= 14727.270508 test loss= 1234.967684
Saved:  _models/sweep/w-50_d-4_e-20_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 14672.146484 test loss= 1220.110357
Epoch: 0002 train loss= 14615.993164 test loss= 1204.666639
Saved:  _models/sweep/w-50_d-4_e-22_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 14558.556641 test loss= 1189.015128
Epoch: 0002 train loss= 14500.090820 test loss= 1172.578701
Saved:  _models/sweep/w-50_d-4_e-24_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 14440.408203 test loss= 1155.997774
Epoch: 0002 train loss= 14379.102539 test loss= 1138.229227
Saved:  _models/sweep/w-50_d-4_e-26_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 14316.416992 test loss= 1120.704915
Epoch: 0002 train loss= 14251.731445 test loss= 1102.132742
Saved:  _models/sweep/w-50_d-4_e-28_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 14185.066406 test loss= 1083.563008
Epoch: 0002 train loss= 14116.264648 test loss= 1064.075961
Saved:  _models/sweep/w-50_d-4_e-30_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 14045.677734 test loss= 1044.852040
Epoch: 0002 train loss= 13972.740234 test loss= 1025.001175
Saved:  _models/sweep/w-50_d-4_e-32_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 13896.614258 test loss= 1005.717880
Epoch: 0002 train loss= 13818.745117 test loss= 985.674195
Saved:  _models/sweep/w-50_d-4_e-34_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 13738.543945 test loss= 966.097681
Epoch: 0002 train loss= 13656.358398 test loss= 945.966255
Saved:  _models/sweep/w-50_d-4_e-36_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 13570.514648 test loss= 925.645841
Epoch: 0002 train loss= 13482.505859 test loss= 905.505217
Saved:  _models/sweep/w-50_d-4_e-38_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 13392.360352 test loss= 885.736755
Epoch: 0002 train loss= 13298.961914 test loss= 865.556560
Saved:  _models/sweep/w-50_d-4_e-40_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 13201.116211 test loss= 845.831349
Epoch: 0002 train loss= 13101.639648 test loss= 826.279953
Saved:  _models/sweep/w-50_d-4_e-42_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 12999.141602 test loss= 807.040797
Epoch: 0002 train loss= 12893.686523 test loss= 788.250659
Saved:  _models/sweep/w-50_d-4_e-44_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 12784.191406 test loss= 769.788786
Epoch: 0002 train loss= 12672.008789 test loss= 751.722990
Saved:  _models/sweep/w-50_d-4_e-46_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 12556.225586 test loss= 734.187655
Epoch: 0002 train loss= 12438.177734 test loss= 717.171679
Saved:  _models/sweep/w-50_d-4_e-48_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 12316.406250 test loss= 700.531192
Epoch: 0002 train loss= 12191.379883 test loss= 684.519445
Saved:  _models/sweep/w-50_d-4_e-50_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 12063.820312 test loss= 669.393648
Epoch: 0002 train loss= 11933.934570 test loss= 654.809652
Saved:  _models/sweep/w-50_d-4_e-52_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 11801.060547 test loss= 641.156729
Epoch: 0002 train loss= 11665.058594 test loss= 627.884619
Saved:  _models/sweep/w-50_d-4_e-54_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 11526.701172 test loss= 615.635851
Epoch: 0002 train loss= 11385.996094 test loss= 603.875219
Saved:  _models/sweep/w-50_d-4_e-56_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 11243.456055 test loss= 593.029686
Epoch: 0002 train loss= 11098.627930 test loss= 582.753730
Saved:  _models/sweep/w-50_d-4_e-58_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 10951.186523 test loss= 573.188685
Epoch: 0002 train loss= 10802.178711 test loss= 564.446568
Saved:  _models/sweep/w-50_d-4_e-60_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 10651.032227 test loss= 556.481952
Epoch: 0002 train loss= 10498.115234 test loss= 549.101326
Saved:  _models/sweep/w-50_d-4_e-62_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 10344.388672 test loss= 542.495882
Epoch: 0002 train loss= 10188.207031 test loss= 536.495279
Saved:  _models/sweep/w-50_d-4_e-64_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 10029.378906 test loss= 531.300532
Epoch: 0002 train loss= 9870.165039 test loss= 526.678307
Saved:  _models/sweep/w-50_d-4_e-66_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 9706.635742 test loss= 522.879757
Epoch: 0002 train loss= 9544.354492 test loss= 519.614986
Saved:  _models/sweep/w-50_d-4_e-68_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 9381.406250 test loss= 517.120094
Epoch: 0002 train loss= 9218.650391 test loss= 515.472982
Saved:  _models/sweep/w-50_d-4_e-70_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 9052.881836 test loss= 514.601134
Epoch: 0002 train loss= 8889.004883 test loss= 514.424789
Saved:  _models/sweep/w-50_d-4_e-72_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 8725.785156 test loss= 515.360872
Epoch: 0002 train loss= 8562.303711 test loss= 517.383965
------------------------------Completed Depth=4	Width= 50 !------------------------------
------------------------------Running Depth= 1 	Width= 100 ------------------------------
Epoch: 0001 train loss= 17017.058594 test loss= 126556.040802
Epoch: 0002 train loss= 16698.417969 test loss= 87811.870760
Saved:  _models/sweep/w-100_d-1_e-2_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 16386.552734 test loss= 61980.324344
Epoch: 0002 train loss= 16085.183594 test loss= 43415.106133
Saved:  _models/sweep/w-100_d-1_e-4_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 15787.145508 test loss= 30477.191242
Epoch: 0002 train loss= 15499.271484 test loss= 21633.374489
Saved:  _models/sweep/w-100_d-1_e-6_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 15217.390625 test loss= 15279.442159
Epoch: 0002 train loss= 14944.183594 test loss= 11135.724504
Saved:  _models/sweep/w-100_d-1_e-8_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 14678.038086 test loss= 8092.235486
Epoch: 0002 train loss= 14416.371094 test loss= 5966.886086
Saved:  _models/sweep/w-100_d-1_e-10_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 14159.630859 test loss= 4509.717704
Epoch: 0002 train loss= 13907.801758 test loss= 3459.351217
Saved:  _models/sweep/w-100_d-1_e-12_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 13658.255859 test loss= 2728.062806
Epoch: 0002 train loss= 13413.903320 test loss= 2198.178128
Saved:  _models/sweep/w-100_d-1_e-14_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 13171.269531 test loss= 1810.552019
Epoch: 0002 train loss= 12932.542969 test loss= 1519.222374
Saved:  _models/sweep/w-100_d-1_e-16_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 12697.514648 test loss= 1301.521681
Epoch: 0002 train loss= 12465.113281 test loss= 1137.864731
Saved:  _models/sweep/w-100_d-1_e-18_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 12233.265625 test loss= 1010.619347
Epoch: 0002 train loss= 12006.484375 test loss= 911.220123
Saved:  _models/sweep/w-100_d-1_e-20_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 11781.290039 test loss= 830.995814
Epoch: 0002 train loss= 11559.115234 test loss= 767.199247
Saved:  _models/sweep/w-100_d-1_e-22_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 11338.441406 test loss= 712.640117
Epoch: 0002 train loss= 11120.377930 test loss= 667.531847
Saved:  _models/sweep/w-100_d-1_e-24_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 10902.269531 test loss= 627.802274
Epoch: 0002 train loss= 10686.844727 test loss= 594.910871
Saved:  _models/sweep/w-100_d-1_e-26_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 10473.400391 test loss= 565.811986
Epoch: 0002 train loss= 10263.208984 test loss= 540.202421
Saved:  _models/sweep/w-100_d-1_e-28_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 10051.719727 test loss= 516.682612
Epoch: 0002 train loss= 9844.417969 test loss= 496.384663
Saved:  _models/sweep/w-100_d-1_e-30_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 9639.504883 test loss= 477.714089
Epoch: 0002 train loss= 9436.468750 test loss= 460.841124
Saved:  _models/sweep/w-100_d-1_e-32_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 9235.344727 test loss= 445.248411
Epoch: 0002 train loss= 9037.177734 test loss= 430.848329
Saved:  _models/sweep/w-100_d-1_e-34_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 8840.992188 test loss= 417.348470
Epoch: 0002 train loss= 8647.828125 test loss= 404.767415
Saved:  _models/sweep/w-100_d-1_e-36_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 8453.845703 test loss= 392.595194
Epoch: 0002 train loss= 8264.574219 test loss= 381.427485
Saved:  _models/sweep/w-100_d-1_e-38_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 8076.033203 test loss= 370.651828
Epoch: 0002 train loss= 7891.980957 test loss= 360.633522
Saved:  _models/sweep/w-100_d-1_e-40_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 7711.069824 test loss= 351.128587
Epoch: 0002 train loss= 7532.370605 test loss= 341.990934
Saved:  _models/sweep/w-100_d-1_e-42_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 7355.753418 test loss= 333.173018
Epoch: 0002 train loss= 7182.327637 test loss= 324.956009
Saved:  _models/sweep/w-100_d-1_e-44_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 7012.333496 test loss= 317.094653
Epoch: 0002 train loss= 6845.477539 test loss= 309.579944
Saved:  _models/sweep/w-100_d-1_e-46_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 6681.890625 test loss= 302.486782
Epoch: 0002 train loss= 6521.273926 test loss= 295.599929
Saved:  _models/sweep/w-100_d-1_e-48_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 6362.654785 test loss= 288.911084
Epoch: 0002 train loss= 6208.387207 test loss= 282.680819
Saved:  _models/sweep/w-100_d-1_e-50_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 6058.002441 test loss= 276.783759
Epoch: 0002 train loss= 5911.215332 test loss= 271.137491
Saved:  _models/sweep/w-100_d-1_e-52_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 5768.506836 test loss= 265.797636
Epoch: 0002 train loss= 5628.784668 test loss= 260.731837
Saved:  _models/sweep/w-100_d-1_e-54_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 5491.673340 test loss= 255.883457
Epoch: 0002 train loss= 5358.505371 test loss= 251.380232
Saved:  _models/sweep/w-100_d-1_e-56_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 5229.745117 test loss= 247.105740
Epoch: 0002 train loss= 5104.450195 test loss= inf
------------------------------Completed Depth=1	Width= 100 !------------------------------
------------------------------Running Depth= 2 	Width= 100 ------------------------------
Epoch: 0001 train loss= 15133.986328 test loss= 836.216737
Epoch: 0002 train loss= 14920.383789 test loss= 805.782947
Saved:  _models/sweep/w-100_d-2_e-2_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 14704.606445 test loss= 777.157681
Epoch: 0002 train loss= 14490.796875 test loss= 750.593612
Saved:  _models/sweep/w-100_d-2_e-4_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 14276.585938 test loss= 725.694315
Epoch: 0002 train loss= 14061.051758 test loss= 701.580609
Saved:  _models/sweep/w-100_d-2_e-6_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 13842.866211 test loss= 678.627123
Epoch: 0002 train loss= 13623.138672 test loss= 656.671074
Saved:  _models/sweep/w-100_d-2_e-8_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 13397.192383 test loss= 635.459713
Epoch: 0002 train loss= 13171.373047 test loss= 615.597361
Saved:  _models/sweep/w-100_d-2_e-10_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 12943.410156 test loss= 596.611501
Epoch: 0002 train loss= 12711.432617 test loss= 578.531991
Saved:  _models/sweep/w-100_d-2_e-12_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 12474.316406 test loss= 560.931955
Epoch: 0002 train loss= 12234.491211 test loss= 543.793284
Saved:  _models/sweep/w-100_d-2_e-14_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 11989.775391 test loss= 527.127325
Epoch: 0002 train loss= 11741.703125 test loss= 510.608016
Saved:  _models/sweep/w-100_d-2_e-16_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 11489.575195 test loss= 494.579038
Epoch: 0002 train loss= 11233.580078 test loss= 478.671850
Saved:  _models/sweep/w-100_d-2_e-18_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 10972.738281 test loss= 463.047152
Epoch: 0002 train loss= 10708.551758 test loss= 447.693232
Saved:  _models/sweep/w-100_d-2_e-20_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 10439.382812 test loss= 432.654650
Epoch: 0002 train loss= 10169.682617 test loss= 417.985633
Saved:  _models/sweep/w-100_d-2_e-22_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 9894.451172 test loss= 403.261792
Epoch: 0002 train loss= 9621.748047 test loss= 389.248397
Saved:  _models/sweep/w-100_d-2_e-24_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 9349.443359 test loss= 375.640348
Epoch: 0002 train loss= 9078.353516 test loss= 362.418526
Saved:  _models/sweep/w-100_d-2_e-26_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 8806.830078 test loss= 349.447074
Epoch: 0002 train loss= 8538.545898 test loss= 337.057004
Saved:  _models/sweep/w-100_d-2_e-28_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 8272.823242 test loss= 325.090135
Epoch: 0002 train loss= 8010.913574 test loss= 313.591255
Saved:  _models/sweep/w-100_d-2_e-30_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 7753.115234 test loss= 302.508659
Epoch: 0002 train loss= 7499.868164 test loss= 291.957364
Saved:  _models/sweep/w-100_d-2_e-32_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 7249.235840 test loss= 281.698508
Epoch: 0002 train loss= 7007.341309 test loss= 272.245722
Saved:  _models/sweep/w-100_d-2_e-34_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 6773.071777 test loss= 263.137186
Epoch: 0002 train loss= 6546.316406 test loss= 254.685119
Saved:  _models/sweep/w-100_d-2_e-36_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 6326.680176 test loss= 246.656839
Epoch: 0002 train loss= 6117.463867 test loss= inf
------------------------------Completed Depth=2	Width= 100 !------------------------------
------------------------------Running Depth= 3 	Width= 100 ------------------------------
Epoch: 0001 train loss= 14432.012695 test loss= 1408.999769
Epoch: 0002 train loss= 14319.738281 test loss= 1364.660235
Saved:  _models/sweep/w-100_d-3_e-2_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 14205.773438 test loss= 1321.803629
Epoch: 0002 train loss= 14090.124023 test loss= 1272.846453
Saved:  _models/sweep/w-100_d-3_e-4_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 13972.448242 test loss= 1223.768625
Epoch: 0002 train loss= 13851.822266 test loss= 1171.281347
Saved:  _models/sweep/w-100_d-3_e-6_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 13728.568359 test loss= 1117.659606
Epoch: 0002 train loss= 13600.971680 test loss= 1066.046270
Saved:  _models/sweep/w-100_d-3_e-8_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 13469.096680 test loss= 1017.983671
Epoch: 0002 train loss= 13332.121094 test loss= 969.710124
Saved:  _models/sweep/w-100_d-3_e-10_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 13190.196289 test loss= 924.300177
Epoch: 0002 train loss= 13043.142578 test loss= 880.028670
Saved:  _models/sweep/w-100_d-3_e-12_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 12890.067383 test loss= 838.461461
Epoch: 0002 train loss= 12731.061523 test loss= 798.514634
Saved:  _models/sweep/w-100_d-3_e-14_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 12566.056641 test loss= 760.514517
Epoch: 0002 train loss= 12393.338867 test loss= 722.877961
Saved:  _models/sweep/w-100_d-3_e-16_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 12213.633789 test loss= 686.847398
Epoch: 0002 train loss= 12026.904297 test loss= 652.130394
Saved:  _models/sweep/w-100_d-3_e-18_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 11830.365234 test loss= 619.348465
Epoch: 0002 train loss= 11626.730469 test loss= 587.923324
Saved:  _models/sweep/w-100_d-3_e-20_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 11414.876953 test loss= 558.430297
Epoch: 0002 train loss= 11194.750977 test loss= 530.242449
Saved:  _models/sweep/w-100_d-3_e-22_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 10966.269531 test loss= 504.140391
Epoch: 0002 train loss= 10728.186523 test loss= 479.273279
Saved:  _models/sweep/w-100_d-3_e-24_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 10481.432617 test loss= 456.207466
Epoch: 0002 train loss= 10228.378906 test loss= 434.563556
Saved:  _models/sweep/w-100_d-3_e-26_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 9966.816406 test loss= 414.080581
Epoch: 0002 train loss= 9700.766602 test loss= 394.885776
Saved:  _models/sweep/w-100_d-3_e-28_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 9427.718750 test loss= 376.787812
Epoch: 0002 train loss= 9151.393555 test loss= 359.515617
Saved:  _models/sweep/w-100_d-3_e-30_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 8870.358398 test loss= 343.044093
Epoch: 0002 train loss= 8587.655273 test loss= 327.338926
Saved:  _models/sweep/w-100_d-3_e-32_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 8302.912109 test loss= 312.339342
Epoch: 0002 train loss= 8019.742188 test loss= 298.073144
Saved:  _models/sweep/w-100_d-3_e-34_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 7738.316895 test loss= 284.496461
Epoch: 0002 train loss= 7460.960938 test loss= 271.755702
Saved:  _models/sweep/w-100_d-3_e-36_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 7187.205078 test loss= 259.568487
Epoch: 0002 train loss= 6921.104004 test loss= 248.343099
Saved:  _models/sweep/w-100_d-3_e-38_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 6661.924316 test loss= 237.641132
Epoch: 0002 train loss= 6412.934082 test loss= 227.951187
Saved:  _models/sweep/w-100_d-3_e-40_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 6173.906738 test loss= inf
Epoch: 0002 train loss= 5948.774414 test loss= inf
Saved:  _models/sweep/w-100_d-3_e-42_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 5736.180176 test loss= inf
Epoch: 0002 train loss= 5539.532227 test loss= inf
Saved:  _models/sweep/w-100_d-3_e-44_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 5358.620605 test loss= inf
Epoch: 0002 train loss= 5195.399902 test loss= inf
Saved:  _models/sweep/w-100_d-3_e-46_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 5048.835938 test loss= inf
Epoch: 0002 train loss= 4920.757812 test loss= inf
Saved:  _models/sweep/w-100_d-3_e-48_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 4810.057129 test loss= inf
Epoch: 0002 train loss= 4715.513672 test loss= inf
Saved:  _models/sweep/w-100_d-3_e-50_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 4634.571777 test loss= inf
Epoch: 0002 train loss= 4567.427246 test loss= inf
Saved:  _models/sweep/w-100_d-3_e-52_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 4510.022949 test loss= inf
Epoch: 0002 train loss= 4460.437988 test loss= inf
Saved:  _models/sweep/w-100_d-3_e-54_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 4415.974609 test loss= inf
Epoch: 0002 train loss= 4374.890137 test loss= inf
Saved:  _models/sweep/w-100_d-3_e-56_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 4336.004395 test loss= inf
Epoch: 0002 train loss= 4298.479004 test loss= inf
Saved:  _models/sweep/w-100_d-3_e-58_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 4261.673340 test loss= inf
Epoch: 0002 train loss= 4225.448242 test loss= inf
Saved:  _models/sweep/w-100_d-3_e-60_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 4189.928711 test loss= inf
Epoch: 0002 train loss= 4154.754395 test loss= inf
Saved:  _models/sweep/w-100_d-3_e-62_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 4119.389648 test loss= inf
Epoch: 0002 train loss= 4084.186279 test loss= inf
Saved:  _models/sweep/w-100_d-3_e-64_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 4049.011475 test loss= inf
Epoch: 0002 train loss= 4013.928223 test loss= inf
Saved:  _models/sweep/w-100_d-3_e-66_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 3978.370605 test loss= inf
Epoch: 0002 train loss= 3942.432861 test loss= inf
Saved:  _models/sweep/w-100_d-3_e-68_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 3906.006592 test loss= inf
Epoch: 0002 train loss= 3869.078613 test loss= inf
Saved:  _models/sweep/w-100_d-3_e-70_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 3831.209961 test loss= inf
Epoch: 0002 train loss= 3792.640625 test loss= inf
Saved:  _models/sweep/w-100_d-3_e-72_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 3753.445312 test loss= inf
Epoch: 0002 train loss= 3713.223877 test loss= inf
Saved:  _models/sweep/w-100_d-3_e-74_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 3671.905518 test loss= inf
Epoch: 0002 train loss= 3629.556885 test loss= inf
Saved:  _models/sweep/w-100_d-3_e-76_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 3586.132080 test loss= inf
Epoch: 0002 train loss= 3541.701904 test loss= inf
Saved:  _models/sweep/w-100_d-3_e-78_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 3496.133301 test loss= inf
Epoch: 0002 train loss= 3449.633545 test loss= inf
Saved:  _models/sweep/w-100_d-3_e-80_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 3401.798340 test loss= inf
Epoch: 0002 train loss= 3352.827148 test loss= inf
Saved:  _models/sweep/w-100_d-3_e-82_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 3302.682129 test loss= inf
Epoch: 0002 train loss= 3251.348633 test loss= inf
Saved:  _models/sweep/w-100_d-3_e-84_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 3198.852051 test loss= inf
Epoch: 0002 train loss= 3145.340576 test loss= inf
Saved:  _models/sweep/w-100_d-3_e-86_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 3090.904297 test loss= inf
Epoch: 0002 train loss= 3035.260254 test loss= inf
Saved:  _models/sweep/w-100_d-3_e-88_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 2978.557373 test loss= inf
Epoch: 0002 train loss= 2920.913818 test loss= inf
Saved:  _models/sweep/w-100_d-3_e-90_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 2861.989258 test loss= inf
Epoch: 0002 train loss= 2802.246338 test loss= inf
Saved:  _models/sweep/w-100_d-3_e-92_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 2741.742188 test loss= inf
Epoch: 0002 train loss= 2680.515625 test loss= inf
Saved:  _models/sweep/w-100_d-3_e-94_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 2618.425049 test loss= inf
Epoch: 0002 train loss= 2555.821289 test loss= inf
Saved:  _models/sweep/w-100_d-3_e-96_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 2492.428955 test loss= inf
Epoch: 0002 train loss= 2428.878906 test loss= 144.990949
Saved:  _models/sweep/w-100_d-3_e-98_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 2365.072021 test loss= 143.481613
Epoch: 0002 train loss= 2300.830078 test loss= 142.237660
Saved:  _models/sweep/w-100_d-3_e-100_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 2236.271729 test loss= 141.237487
Epoch: 0002 train loss= 2171.510742 test loss= 139.859601
Saved:  _models/sweep/w-100_d-3_e-102_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 2106.456543 test loss= 138.512354
Epoch: 0002 train loss= 2042.119751 test loss= 137.687279
Saved:  _models/sweep/w-100_d-3_e-104_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 1978.239380 test loss= 136.606038
Epoch: 0002 train loss= 1914.715698 test loss= 135.612022
Saved:  _models/sweep/w-100_d-3_e-106_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 1851.346680 test loss= 134.517348
Epoch: 0002 train loss= 1789.039185 test loss= 133.726339
Saved:  _models/sweep/w-100_d-3_e-108_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 1727.382812 test loss= 132.913984
Epoch: 0002 train loss= 1666.592529 test loss= 132.556983
Saved:  _models/sweep/w-100_d-3_e-110_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 1606.673218 test loss= 132.522130
Epoch: 0002 train loss= 1547.807129 test loss= 132.819341
------------------------------Completed Depth=3	Width= 100 !------------------------------
------------------------------Running Depth= 4 	Width= 100 ------------------------------
Epoch: 0001 train loss= 15936.040039 test loss= 1532.689448
Epoch: 0002 train loss= 15849.458008 test loss= 1505.972818
Saved:  _models/sweep/w-100_d-4_e-2_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 15764.486328 test loss= 1479.807511
Epoch: 0002 train loss= 15680.819336 test loss= 1449.048836
Saved:  _models/sweep/w-100_d-4_e-4_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 15595.770508 test loss= 1415.127230
Epoch: 0002 train loss= 15508.100586 test loss= 1378.875917
Saved:  _models/sweep/w-100_d-4_e-6_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 15416.472656 test loss= 1341.295726
Epoch: 0002 train loss= 15323.075195 test loss= 1302.536230
Saved:  _models/sweep/w-100_d-4_e-8_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 15227.011719 test loss= 1261.815177
Epoch: 0002 train loss= 15125.837891 test loss= 1215.439587
Saved:  _models/sweep/w-100_d-4_e-10_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 15019.888672 test loss= 1166.480497
Epoch: 0002 train loss= 14908.862305 test loss= 1114.052573
Saved:  _models/sweep/w-100_d-4_e-12_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 14792.170898 test loss= 1061.466830
Epoch: 0002 train loss= 14667.699219 test loss= 1008.218546
Saved:  _models/sweep/w-100_d-4_e-14_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 14535.849609 test loss= 958.795499
Epoch: 0002 train loss= 14395.423828 test loss= 908.627103
Saved:  _models/sweep/w-100_d-4_e-16_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 14245.166992 test loss= 860.833971
Epoch: 0002 train loss= 14086.046875 test loss= 813.704745
Saved:  _models/sweep/w-100_d-4_e-18_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 13917.403320 test loss= 770.672067
Epoch: 0002 train loss= 13736.346680 test loss= 728.272395
Saved:  _models/sweep/w-100_d-4_e-20_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 13542.123047 test loss= 689.390088
Epoch: 0002 train loss= 13331.617188 test loss= 651.433110
Saved:  _models/sweep/w-100_d-4_e-22_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 13104.191406 test loss= 617.490270
Epoch: 0002 train loss= 12860.389648 test loss= 585.376233
Saved:  _models/sweep/w-100_d-4_e-24_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 12599.103516 test loss= 556.597195
Epoch: 0002 train loss= 12324.588867 test loss= 529.473972
Saved:  _models/sweep/w-100_d-4_e-26_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 12031.234375 test loss= 504.305968
Epoch: 0002 train loss= 11724.967773 test loss= 480.345592
Saved:  _models/sweep/w-100_d-4_e-28_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 11403.382812 test loss= 457.857455
Epoch: 0002 train loss= 11070.022461 test loss= 435.933620
Saved:  _models/sweep/w-100_d-4_e-30_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 10723.618164 test loss= 414.935318
Epoch: 0002 train loss= 10365.813477 test loss= 394.156654
Saved:  _models/sweep/w-100_d-4_e-32_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 9998.248047 test loss= 374.040697
Epoch: 0002 train loss= 9623.421875 test loss= 354.032468
Saved:  _models/sweep/w-100_d-4_e-34_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 9238.879883 test loss= 334.491635
Epoch: 0002 train loss= 8856.752930 test loss= 315.603290
Saved:  _models/sweep/w-100_d-4_e-36_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 8474.537109 test loss= 297.316687
Epoch: 0002 train loss= 8097.544922 test loss= 279.867507
Saved:  _models/sweep/w-100_d-4_e-38_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 7726.912109 test loss= 263.138017
Epoch: 0002 train loss= 7367.682617 test loss= 247.643633
Saved:  _models/sweep/w-100_d-4_e-40_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 7021.772949 test loss= inf
Epoch: 0002 train loss= 6695.683594 test loss= inf
Saved:  _models/sweep/w-100_d-4_e-42_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 6390.774902 test loss= inf
Epoch: 0002 train loss= 6112.798340 test loss= inf
Saved:  _models/sweep/w-100_d-4_e-44_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 5861.709473 test loss= inf
Epoch: 0002 train loss= 5641.560059 test loss= inf
Saved:  _models/sweep/w-100_d-4_e-46_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 5450.683105 test loss= inf
Epoch: 0002 train loss= 5293.936035 test loss= inf
Saved:  _models/sweep/w-100_d-4_e-48_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 5167.980957 test loss= inf
Epoch: 0002 train loss= 5073.097168 test loss= inf
Saved:  _models/sweep/w-100_d-4_e-50_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 5003.638672 test loss= inf
Epoch: 0002 train loss= 4953.368652 test loss= inf
Saved:  _models/sweep/w-100_d-4_e-52_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 4914.187988 test loss= inf
Epoch: 0002 train loss= 4880.141602 test loss= inf
Saved:  _models/sweep/w-100_d-4_e-54_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 4848.393555 test loss= inf
Epoch: 0002 train loss= 4817.670898 test loss= inf
Saved:  _models/sweep/w-100_d-4_e-56_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 4787.403320 test loss= inf
Epoch: 0002 train loss= 4757.341797 test loss= inf
Saved:  _models/sweep/w-100_d-4_e-58_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 4727.466797 test loss= inf
Epoch: 0002 train loss= 4697.227051 test loss= inf
Saved:  _models/sweep/w-100_d-4_e-60_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 4666.268066 test loss= inf
Epoch: 0002 train loss= 4635.158203 test loss= inf
Saved:  _models/sweep/w-100_d-4_e-62_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 4603.477539 test loss= inf
Epoch: 0002 train loss= 4571.305176 test loss= inf
Saved:  _models/sweep/w-100_d-4_e-64_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 4538.564453 test loss= inf
Epoch: 0002 train loss= 4505.456543 test loss= inf
Saved:  _models/sweep/w-100_d-4_e-66_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 4472.271484 test loss= inf
Epoch: 0002 train loss= 4439.030762 test loss= inf
Saved:  _models/sweep/w-100_d-4_e-68_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 4405.868164 test loss= inf
Epoch: 0002 train loss= 4373.095215 test loss= inf
Saved:  _models/sweep/w-100_d-4_e-70_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 4340.797363 test loss= inf
Epoch: 0002 train loss= 4308.929688 test loss= inf
Saved:  _models/sweep/w-100_d-4_e-72_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 4277.520508 test loss= inf
Epoch: 0002 train loss= 4246.645996 test loss= inf
Saved:  _models/sweep/w-100_d-4_e-74_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 4215.877441 test loss= inf
Epoch: 0002 train loss= 4185.201172 test loss= inf
Saved:  _models/sweep/w-100_d-4_e-76_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 4154.430664 test loss= inf
Epoch: 0002 train loss= 4124.053223 test loss= inf
Saved:  _models/sweep/w-100_d-4_e-78_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 4093.762939 test loss= inf
Epoch: 0002 train loss= 4063.272949 test loss= inf
Saved:  _models/sweep/w-100_d-4_e-80_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 4032.313477 test loss= inf
Epoch: 0002 train loss= 4000.940918 test loss= inf
Saved:  _models/sweep/w-100_d-4_e-82_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 3969.007812 test loss= inf
Epoch: 0002 train loss= 3936.510010 test loss= inf
Saved:  _models/sweep/w-100_d-4_e-84_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 3903.393066 test loss= inf
Epoch: 0002 train loss= 3869.543213 test loss= inf
Saved:  _models/sweep/w-100_d-4_e-86_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 3834.490723 test loss= inf
Epoch: 0002 train loss= 3798.622803 test loss= inf
Saved:  _models/sweep/w-100_d-4_e-88_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 3761.781738 test loss= inf
Epoch: 0002 train loss= 3723.707520 test loss= inf
Saved:  _models/sweep/w-100_d-4_e-90_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 3684.573486 test loss= inf
Epoch: 0002 train loss= 3644.719971 test loss= inf
Saved:  _models/sweep/w-100_d-4_e-92_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 3603.780029 test loss= inf
Epoch: 0002 train loss= 3562.184814 test loss= inf
Saved:  _models/sweep/w-100_d-4_e-94_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 3519.687500 test loss= inf
Epoch: 0002 train loss= 3476.607422 test loss= inf
Saved:  _models/sweep/w-100_d-4_e-96_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 3432.550537 test loss= inf
Epoch: 0002 train loss= 3387.649414 test loss= inf
Saved:  _models/sweep/w-100_d-4_e-98_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 3341.770264 test loss= inf
Epoch: 0002 train loss= 3295.362549 test loss= inf
Saved:  _models/sweep/w-100_d-4_e-100_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 3248.350342 test loss= inf
Epoch: 0002 train loss= 3201.060303 test loss= inf
Saved:  _models/sweep/w-100_d-4_e-102_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 3153.444092 test loss= inf
Epoch: 0002 train loss= 3105.733643 test loss= inf
Saved:  _models/sweep/w-100_d-4_e-104_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 3057.926514 test loss= inf
Epoch: 0002 train loss= 3009.918701 test loss= inf
Saved:  _models/sweep/w-100_d-4_e-106_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 2961.691650 test loss= inf
Epoch: 0002 train loss= 2913.559814 test loss= inf
Saved:  _models/sweep/w-100_d-4_e-108_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 2865.019287 test loss= inf
Epoch: 0002 train loss= 2816.296875 test loss= inf
Saved:  _models/sweep/w-100_d-4_e-110_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 2767.354248 test loss= inf
Epoch: 0002 train loss= 2718.008545 test loss= inf
Saved:  _models/sweep/w-100_d-4_e-112_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 2668.268066 test loss= inf
Epoch: 0002 train loss= 2618.163818 test loss= inf
Saved:  _models/sweep/w-100_d-4_e-114_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 2567.897705 test loss= inf
Epoch: 0002 train loss= 2517.212158 test loss= inf
Saved:  _models/sweep/w-100_d-4_e-116_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 2466.295654 test loss= inf
Epoch: 0002 train loss= 2415.005615 test loss= inf
Saved:  _models/sweep/w-100_d-4_e-118_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 2363.293457 test loss= inf
Epoch: 0002 train loss= 2311.559082 test loss= inf
Saved:  _models/sweep/w-100_d-4_e-120_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 2259.858887 test loss= 1927187.644123
Epoch: 0002 train loss= 2208.616211 test loss= 6464863.153815
------------------------------Completed Depth=4	Width= 100 !------------------------------
------------------------------Running Depth= 1 	Width= 150 ------------------------------
Epoch: 0001 train loss= 14589.218750 test loss= 3135.971568
Epoch: 0002 train loss= 14068.931641 test loss= 2392.091728
Saved:  _models/sweep/w-150_d-1_e-2_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 13565.000977 test loss= 1872.010696
Epoch: 0002 train loss= 13086.386719 test loss= 1509.158391
Saved:  _models/sweep/w-150_d-1_e-4_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 12617.911133 test loss= 1225.932306
Epoch: 0002 train loss= 12169.378906 test loss= 1034.087619
Saved:  _models/sweep/w-150_d-1_e-6_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 11733.523438 test loss= 884.610460
Epoch: 0002 train loss= 11314.090820 test loss= 777.585242
Saved:  _models/sweep/w-150_d-1_e-8_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 10904.594727 test loss= 692.686463
Epoch: 0002 train loss= 10510.407227 test loss= 627.887930
Saved:  _models/sweep/w-150_d-1_e-10_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 10128.112305 test loss= 575.536001
Epoch: 0002 train loss= 9757.323242 test loss= 532.583231
Saved:  _models/sweep/w-150_d-1_e-12_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 9397.868164 test loss= 496.540492
Epoch: 0002 train loss= 9050.066406 test loss= 466.357809
Saved:  _models/sweep/w-150_d-1_e-14_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 8709.975586 test loss= 439.192274
Epoch: 0002 train loss= 8381.938477 test loss= 415.803264
Saved:  _models/sweep/w-150_d-1_e-16_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 8064.759277 test loss= 394.847456
Epoch: 0002 train loss= 7758.522461 test loss= 376.351946
Saved:  _models/sweep/w-150_d-1_e-18_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 7462.600586 test loss= 359.278749
Epoch: 0002 train loss= 7177.236816 test loss= 343.743728
Saved:  _models/sweep/w-150_d-1_e-20_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 6901.732910 test loss= 328.949331
Epoch: 0002 train loss= 6637.172852 test loss= 315.449933
Saved:  _models/sweep/w-150_d-1_e-22_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 6382.390625 test loss= 302.652705
Epoch: 0002 train loss= 6139.320312 test loss= 290.734807
Saved:  _models/sweep/w-150_d-1_e-24_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 5905.900391 test loss= 279.400821
Epoch: 0002 train loss= 5684.452148 test loss= 268.900667
Saved:  _models/sweep/w-150_d-1_e-26_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 5472.909180 test loss= 258.797370
Epoch: 0002 train loss= 5273.170898 test loss= 249.312950
Saved:  _models/sweep/w-150_d-1_e-28_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 5083.315918 test loss= 240.321403
Epoch: 0002 train loss= 4904.328125 test loss= 231.966769
Saved:  _models/sweep/w-150_d-1_e-30_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 4734.120117 test loss= 224.004272
Epoch: 0002 train loss= 4575.199219 test loss= 216.708826
Saved:  _models/sweep/w-150_d-1_e-32_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 4424.938477 test loss= 209.658722
Epoch: 0002 train loss= 4285.031250 test loss= 203.427361
Saved:  _models/sweep/w-150_d-1_e-34_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 4154.818359 test loss= 197.636590
Epoch: 0002 train loss= 4032.700439 test loss= 192.064490
Saved:  _models/sweep/w-150_d-1_e-36_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 3917.882568 test loss= 186.906424
Epoch: 0002 train loss= 3810.720459 test loss= 182.217844
Saved:  _models/sweep/w-150_d-1_e-38_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 3709.626953 test loss= 177.765110
Epoch: 0002 train loss= 3614.944580 test loss= 173.663114
Saved:  _models/sweep/w-150_d-1_e-40_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 3524.922119 test loss= 169.876170
Epoch: 0002 train loss= 3439.482422 test loss= 166.393090
Saved:  _models/sweep/w-150_d-1_e-42_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 3357.617920 test loss= 163.086343
Epoch: 0002 train loss= 3278.817627 test loss= 159.975142
Saved:  _models/sweep/w-150_d-1_e-44_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 3202.412109 test loss= 156.929616
Epoch: 0002 train loss= 3127.782227 test loss= 154.184279
Saved:  _models/sweep/w-150_d-1_e-46_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 3054.542236 test loss= 151.568146
Epoch: 0002 train loss= 2982.228760 test loss= 148.989389
Saved:  _models/sweep/w-150_d-1_e-48_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 2910.573730 test loss= 146.656944
Epoch: 0002 train loss= 2839.521729 test loss= 144.299004
Saved:  _models/sweep/w-150_d-1_e-50_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 2768.688477 test loss= 142.078603
Epoch: 0002 train loss= 2698.177246 test loss= 140.063683
Saved:  _models/sweep/w-150_d-1_e-52_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 2627.558594 test loss= 138.043867
Epoch: 0002 train loss= 2557.091553 test loss= 136.157026
Saved:  _models/sweep/w-150_d-1_e-54_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 2486.554199 test loss= 134.373261
Epoch: 0002 train loss= 2416.413574 test loss= 132.640021
Saved:  _models/sweep/w-150_d-1_e-56_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 2346.254883 test loss= 131.061264
Epoch: 0002 train loss= 2276.053955 test loss= 129.515346
Saved:  _models/sweep/w-150_d-1_e-58_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 2205.848633 test loss= 127.965913
Epoch: 0002 train loss= 2136.177734 test loss= 126.650529
Saved:  _models/sweep/w-150_d-1_e-60_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 2066.557617 test loss= 125.469088
Epoch: 0002 train loss= 1997.102173 test loss= 124.450841
Saved:  _models/sweep/w-150_d-1_e-62_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 1928.023193 test loss= 123.542002
Epoch: 0002 train loss= 1859.392700 test loss= 122.901627
Saved:  _models/sweep/w-150_d-1_e-64_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 1790.740967 test loss= 122.610015
Epoch: 0002 train loss= 1722.923096 test loss= 122.521617
------------------------------Completed Depth=1	Width= 150 !------------------------------
------------------------------Running Depth= 2 	Width= 150 ------------------------------
Epoch: 0001 train loss= 16268.125977 test loss= 2606.987188
Epoch: 0002 train loss= 15905.056641 test loss= 2188.146858
Saved:  _models/sweep/w-150_d-2_e-2_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 15541.679688 test loss= 1860.119706
Epoch: 0002 train loss= 15190.626953 test loss= 1612.930772
Saved:  _models/sweep/w-150_d-2_e-4_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 14838.643555 test loss= 1401.524254
Epoch: 0002 train loss= 14490.456055 test loss= 1234.447478
Saved:  _models/sweep/w-150_d-2_e-6_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 14137.475586 test loss= 1091.958630
Epoch: 0002 train loss= 13786.521484 test loss= 974.327684
Saved:  _models/sweep/w-150_d-2_e-8_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 13434.132812 test loss= 878.956752
Epoch: 0002 train loss= 13080.743164 test loss= 793.943726
Saved:  _models/sweep/w-150_d-2_e-10_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 12720.367188 test loss= 720.989343
Epoch: 0002 train loss= 12359.946289 test loss= 660.587982
Saved:  _models/sweep/w-150_d-2_e-12_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 11991.732422 test loss= 608.285482
Epoch: 0002 train loss= 11623.888672 test loss= 565.795050
Saved:  _models/sweep/w-150_d-2_e-14_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 11253.687500 test loss= 529.211712
Epoch: 0002 train loss= 10881.334961 test loss= 496.731646
Saved:  _models/sweep/w-150_d-2_e-16_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 10504.570312 test loss= 467.063242
Epoch: 0002 train loss= 10127.223633 test loss= 440.487473
Saved:  _models/sweep/w-150_d-2_e-18_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 9749.750977 test loss= 415.917254
Epoch: 0002 train loss= 9373.958984 test loss= 393.028756
Saved:  _models/sweep/w-150_d-2_e-20_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 8998.153320 test loss= 371.387227
Epoch: 0002 train loss= 8628.847656 test loss= 351.527166
Saved:  _models/sweep/w-150_d-2_e-22_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 8264.047852 test loss= 332.745870
Epoch: 0002 train loss= 7906.701172 test loss= 315.271288
Saved:  _models/sweep/w-150_d-2_e-24_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 7555.999512 test loss= 298.723941
Epoch: 0002 train loss= 7216.193848 test loss= 283.550912
Saved:  _models/sweep/w-150_d-2_e-26_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 6885.671387 test loss= 269.222641
Epoch: 0002 train loss= 6568.792969 test loss= 256.202296
Saved:  _models/sweep/w-150_d-2_e-28_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 6263.825195 test loss= 243.983319
Epoch: 0002 train loss= 5973.972168 test loss= 233.011117
Saved:  _models/sweep/w-150_d-2_e-30_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 5699.315918 test loss= 222.786265
Epoch: 0002 train loss= 5440.717285 test loss= inf
------------------------------Completed Depth=2	Width= 150 !------------------------------
------------------------------Running Depth= 3 	Width= 150 ------------------------------
Epoch: 0001 train loss= 14809.200195 test loss= 1326.688925
Epoch: 0002 train loss= 14643.573242 test loss= 1263.672377
Saved:  _models/sweep/w-150_d-3_e-2_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 14472.725586 test loss= 1196.648629
Epoch: 0002 train loss= 14296.507812 test loss= 1130.915754
Saved:  _models/sweep/w-150_d-3_e-4_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 14113.482422 test loss= 1065.642684
Epoch: 0002 train loss= 13918.791992 test loss= 999.562519
Saved:  _models/sweep/w-150_d-3_e-6_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 13712.915039 test loss= 937.134391
Epoch: 0002 train loss= 13493.681641 test loss= 872.878149
Saved:  _models/sweep/w-150_d-3_e-8_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 13261.396484 test loss= 813.392120
Epoch: 0002 train loss= 13009.152344 test loss= 750.760206
Saved:  _models/sweep/w-150_d-3_e-10_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 12739.350586 test loss= 692.898157
Epoch: 0002 train loss= 12449.205078 test loss= 639.137147
Saved:  _models/sweep/w-150_d-3_e-12_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 12138.998047 test loss= 593.039654
Epoch: 0002 train loss= 11811.560547 test loss= 551.317044
Saved:  _models/sweep/w-150_d-3_e-14_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 11459.128906 test loss= 514.676792
Epoch: 0002 train loss= 11093.430664 test loss= 482.526060
Saved:  _models/sweep/w-150_d-3_e-16_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 10706.145508 test loss= 453.985297
Epoch: 0002 train loss= 10305.426758 test loss= 427.797340
Saved:  _models/sweep/w-150_d-3_e-18_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 9888.694336 test loss= 403.923251
Epoch: 0002 train loss= 9462.384766 test loss= 381.472136
Saved:  _models/sweep/w-150_d-3_e-20_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 9026.013672 test loss= 360.268475
Epoch: 0002 train loss= 8587.458008 test loss= 340.139889
Saved:  _models/sweep/w-150_d-3_e-22_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 8155.563965 test loss= 321.412310
Epoch: 0002 train loss= 7727.074707 test loss= 303.590058
Saved:  _models/sweep/w-150_d-3_e-24_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 7303.890625 test loss= 286.760311
Epoch: 0002 train loss= 6899.972168 test loss= 271.339351
Saved:  _models/sweep/w-150_d-3_e-26_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 6516.994629 test loss= 257.157478
Epoch: 0002 train loss= 6160.124023 test loss= 244.375084
Saved:  _models/sweep/w-150_d-3_e-28_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 5831.253418 test loss= inf
Epoch: 0002 train loss= 5537.492676 test loss= inf
Saved:  _models/sweep/w-150_d-3_e-30_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 5277.311523 test loss= inf
Epoch: 0002 train loss= 5057.166016 test loss= inf
Saved:  _models/sweep/w-150_d-3_e-32_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 4873.490723 test loss= inf
Epoch: 0002 train loss= 4725.478027 test loss= inf
Saved:  _models/sweep/w-150_d-3_e-34_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 4607.134766 test loss= inf
Epoch: 0002 train loss= 4513.230469 test loss= inf
Saved:  _models/sweep/w-150_d-3_e-36_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 4435.773926 test loss= inf
Epoch: 0002 train loss= 4367.259766 test loss= inf
Saved:  _models/sweep/w-150_d-3_e-38_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 4303.301758 test loss= inf
Epoch: 0002 train loss= 4240.818359 test loss= inf
Saved:  _models/sweep/w-150_d-3_e-40_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 4178.603027 test loss= inf
Epoch: 0002 train loss= 4116.188965 test loss= inf
Saved:  _models/sweep/w-150_d-3_e-42_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 4053.233887 test loss= inf
Epoch: 0002 train loss= 3989.855957 test loss= inf
Saved:  _models/sweep/w-150_d-3_e-44_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 3925.995605 test loss= inf
Epoch: 0002 train loss= 3861.368164 test loss= inf
Saved:  _models/sweep/w-150_d-3_e-46_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 3795.921143 test loss= inf
Epoch: 0002 train loss= 3729.994873 test loss= inf
Saved:  _models/sweep/w-150_d-3_e-48_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 3662.443848 test loss= inf
Epoch: 0002 train loss= 3593.001221 test loss= inf
Saved:  _models/sweep/w-150_d-3_e-50_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 3521.619141 test loss= inf
Epoch: 0002 train loss= 3448.348633 test loss= inf
Saved:  _models/sweep/w-150_d-3_e-52_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 3373.283203 test loss= inf
Epoch: 0002 train loss= 3296.220215 test loss= inf
Saved:  _models/sweep/w-150_d-3_e-54_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 3216.606445 test loss= inf
Epoch: 0002 train loss= 3134.697998 test loss= inf
Saved:  _models/sweep/w-150_d-3_e-56_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 3050.210449 test loss= inf
Epoch: 0002 train loss= 2963.364746 test loss= inf
Saved:  _models/sweep/w-150_d-3_e-58_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 2873.782471 test loss= inf
Epoch: 0002 train loss= 2782.295654 test loss= inf
Saved:  _models/sweep/w-150_d-3_e-60_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 2688.829346 test loss= inf
Epoch: 0002 train loss= 2593.542969 test loss= inf
Saved:  _models/sweep/w-150_d-3_e-62_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 2496.730469 test loss= inf
Epoch: 0002 train loss= 2398.980713 test loss= inf
Saved:  _models/sweep/w-150_d-3_e-64_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 2300.208984 test loss= 139.595409
Epoch: 0002 train loss= 2200.718262 test loss= 137.707938
Saved:  _models/sweep/w-150_d-3_e-66_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 2100.550781 test loss= 135.624515
Epoch: 0002 train loss= 2000.141479 test loss= 133.066830
Saved:  _models/sweep/w-150_d-3_e-68_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 1899.386475 test loss= 131.437167
Epoch: 0002 train loss= 1799.459229 test loss= 129.962703
Saved:  _models/sweep/w-150_d-3_e-70_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 1699.720093 test loss= 129.663382
Epoch: 0002 train loss= 1600.416748 test loss= 129.412755
Saved:  _models/sweep/w-150_d-3_e-72_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 1500.576904 test loss= 130.014854
Epoch: 0002 train loss= 1401.631470 test loss= 134.455955
------------------------------Completed Depth=3	Width= 150 !------------------------------
------------------------------Running Depth= 4 	Width= 150 ------------------------------
Epoch: 0001 train loss= 15902.464844 test loss= 1604.799770
Epoch: 0002 train loss= 15757.806641 test loss= 1553.004915
Saved:  _models/sweep/w-150_d-4_e-2_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 15616.599609 test loss= 1498.832290
Epoch: 0002 train loss= 15480.159180 test loss= 1449.635973
Saved:  _models/sweep/w-150_d-4_e-4_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 15344.740234 test loss= 1401.858310
Epoch: 0002 train loss= 15204.876953 test loss= 1350.842783
Saved:  _models/sweep/w-150_d-4_e-6_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 15058.795898 test loss= 1295.894968
Epoch: 0002 train loss= 14904.260742 test loss= 1238.075291
Saved:  _models/sweep/w-150_d-4_e-8_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 14738.503906 test loss= 1179.047979
Epoch: 0002 train loss= 14559.328125 test loss= 1115.217603
Saved:  _models/sweep/w-150_d-4_e-10_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 14363.786133 test loss= 1052.507197
Epoch: 0002 train loss= 14147.110352 test loss= 983.570538
Saved:  _models/sweep/w-150_d-4_e-12_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 13906.903320 test loss= 917.865431
Epoch: 0002 train loss= 13641.734375 test loss= 849.635357
Saved:  _models/sweep/w-150_d-4_e-14_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 13348.675781 test loss= 785.426847
Epoch: 0002 train loss= 13031.286133 test loss= 724.335071
Saved:  _models/sweep/w-150_d-4_e-16_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 12683.290039 test loss= 667.301961
Epoch: 0002 train loss= 12305.024414 test loss= 614.300936
Saved:  _models/sweep/w-150_d-4_e-18_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 11898.855469 test loss= 567.039852
Epoch: 0002 train loss= 11455.579102 test loss= 522.131632
Saved:  _models/sweep/w-150_d-4_e-20_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 10981.513672 test loss= 482.322631
Epoch: 0002 train loss= 10476.676758 test loss= 444.624105
Saved:  _models/sweep/w-150_d-4_e-22_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 9949.324219 test loss= 410.677946
Epoch: 0002 train loss= 9399.465820 test loss= 377.999949
Saved:  _models/sweep/w-150_d-4_e-24_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 8834.481445 test loss= 347.453502
Epoch: 0002 train loss= 8268.882812 test loss= 318.756939
Saved:  _models/sweep/w-150_d-4_e-26_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 7708.892090 test loss= 291.920500
Epoch: 0002 train loss= 7169.011230 test loss= 267.530546
Saved:  _models/sweep/w-150_d-4_e-28_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 6662.912598 test loss= 245.329016
Epoch: 0002 train loss= 6202.228027 test loss= inf
------------------------------Completed Depth=4	Width= 150 !------------------------------
------------------------------Running Depth= 1 	Width= 200 ------------------------------
Epoch: 0001 train loss= 14373.664062 test loss= 924.275263
Epoch: 0002 train loss= 13572.597656 test loss= 705.158195
Saved:  _models/sweep/w-200_d-1_e-2_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 12818.048828 test loss= 581.706254
Epoch: 0002 train loss= 12109.692383 test loss= 509.532412
Saved:  _models/sweep/w-200_d-1_e-4_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 11440.135742 test loss= 458.578447
Epoch: 0002 train loss= 10810.092773 test loss= 420.804798
Saved:  _models/sweep/w-200_d-1_e-6_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 10211.542969 test loss= 389.406772
Epoch: 0002 train loss= 9649.726562 test loss= 363.417997
Saved:  _models/sweep/w-200_d-1_e-8_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 9115.732422 test loss= 340.185865
Epoch: 0002 train loss= 8617.433594 test loss= 320.185211
Saved:  _models/sweep/w-200_d-1_e-10_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 8143.275879 test loss= 301.557056
Epoch: 0002 train loss= 7698.217285 test loss= 285.193207
Saved:  _models/sweep/w-200_d-1_e-12_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 7280.144043 test loss= 269.942653
Epoch: 0002 train loss= 6886.100098 test loss= 256.392143
Saved:  _models/sweep/w-200_d-1_e-14_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 6513.941406 test loss= 243.627748
Epoch: 0002 train loss= 6167.645508 test loss= 232.337766
Saved:  _models/sweep/w-200_d-1_e-16_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 5842.994629 test loss= 221.877879
Epoch: 0002 train loss= 5541.042969 test loss= 212.586457
Saved:  _models/sweep/w-200_d-1_e-18_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 5258.951172 test loss= 203.841661
Epoch: 0002 train loss= 4997.689941 test loss= 196.086763
Saved:  _models/sweep/w-200_d-1_e-20_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 4756.298828 test loss= inf
Epoch: 0002 train loss= 4533.072754 test loss= inf
Saved:  _models/sweep/w-200_d-1_e-22_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 4326.531250 test loss= inf
Epoch: 0002 train loss= 4136.742188 test loss= inf
Saved:  _models/sweep/w-200_d-1_e-24_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 3962.489258 test loss= inf
Epoch: 0002 train loss= 3802.719238 test loss= inf
Saved:  _models/sweep/w-200_d-1_e-26_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 3656.180420 test loss= inf
Epoch: 0002 train loss= 3520.448242 test loss= inf
Saved:  _models/sweep/w-200_d-1_e-28_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 3394.395996 test loss= inf
Epoch: 0002 train loss= 3276.531006 test loss= inf
Saved:  _models/sweep/w-200_d-1_e-30_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 3164.583252 test loss= inf
Epoch: 0002 train loss= 3056.985107 test loss= inf
Saved:  _models/sweep/w-200_d-1_e-32_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 2952.024170 test loss= inf
Epoch: 0002 train loss= 2849.497314 test loss= inf
Saved:  _models/sweep/w-200_d-1_e-34_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 2748.023193 test loss= inf
Epoch: 0002 train loss= 2647.468018 test loss= inf
Saved:  _models/sweep/w-200_d-1_e-36_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 2548.185059 test loss= inf
Epoch: 0002 train loss= 2449.134521 test loss= inf
Saved:  _models/sweep/w-200_d-1_e-38_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 2349.674316 test loss= inf
Epoch: 0002 train loss= 2251.187744 test loss= inf
Saved:  _models/sweep/w-200_d-1_e-40_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 2152.594971 test loss= inf
Epoch: 0002 train loss= 2054.778320 test loss= inf
Saved:  _models/sweep/w-200_d-1_e-42_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 1956.879761 test loss= inf
Epoch: 0002 train loss= 1859.611328 test loss= 111.031702
Saved:  _models/sweep/w-200_d-1_e-44_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 1762.574341 test loss= 109.213341
Epoch: 0002 train loss= 1666.347290 test loss= 108.057139
Saved:  _models/sweep/w-200_d-1_e-46_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 1570.766968 test loss= 107.948597
Epoch: 0002 train loss= 1476.042969 test loss= 109.342454
------------------------------Completed Depth=1	Width= 200 !------------------------------
------------------------------Running Depth= 2 	Width= 200 ------------------------------
Epoch: 0001 train loss= 15231.536133 test loss= 1524.063114
Epoch: 0002 train loss= 14719.467773 test loss= 1256.473720
Saved:  _models/sweep/w-200_d-2_e-2_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 14219.493164 test loss= 1048.501201
Epoch: 0002 train loss= 13720.017578 test loss= 890.167470
Saved:  _models/sweep/w-200_d-2_e-4_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 13218.746094 test loss= 769.853219
Epoch: 0002 train loss= 12720.179688 test loss= 679.916748
Saved:  _models/sweep/w-200_d-2_e-6_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 12221.197266 test loss= 610.989593
Epoch: 0002 train loss= 11713.351562 test loss= 552.723199
Saved:  _models/sweep/w-200_d-2_e-8_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 11197.783203 test loss= 505.793021
Epoch: 0002 train loss= 10680.361328 test loss= 466.668311
Saved:  _models/sweep/w-200_d-2_e-10_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 10158.976562 test loss= 433.028098
Epoch: 0002 train loss= 9643.945312 test loss= 403.669616
Saved:  _models/sweep/w-200_d-2_e-12_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 9132.946289 test loss= 377.279101
Epoch: 0002 train loss= 8628.359375 test loss= 353.059679
Saved:  _models/sweep/w-200_d-2_e-14_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 8126.774902 test loss= 330.257766
Epoch: 0002 train loss= 7641.473633 test loss= 309.931741
Saved:  _models/sweep/w-200_d-2_e-16_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 7171.929199 test loss= 290.918410
Epoch: 0002 train loss= 6722.568848 test loss= 273.631453
Saved:  _models/sweep/w-200_d-2_e-18_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 6295.513184 test loss= 257.719848
Epoch: 0002 train loss= 5893.959473 test loss= 243.338742
Saved:  _models/sweep/w-200_d-2_e-20_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 5514.486328 test loss= 229.892781
Epoch: 0002 train loss= 5169.926270 test loss= 218.541304
Saved:  _models/sweep/w-200_d-2_e-22_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 4854.713379 test loss= 207.994182
Epoch: 0002 train loss= 4574.165527 test loss= 199.400200
Saved:  _models/sweep/w-200_d-2_e-24_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 4324.691406 test loss= inf
Epoch: 0002 train loss= 4105.300293 test loss= inf
Saved:  _models/sweep/w-200_d-2_e-26_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 3913.144287 test loss= inf
Epoch: 0002 train loss= 3744.870361 test loss= inf
Saved:  _models/sweep/w-200_d-2_e-28_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 3594.418701 test loss= inf
Epoch: 0002 train loss= 3457.582031 test loss= inf
Saved:  _models/sweep/w-200_d-2_e-30_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 3328.927734 test loss= inf
Epoch: 0002 train loss= 3204.711670 test loss= inf
Saved:  _models/sweep/w-200_d-2_e-32_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 3081.663818 test loss= inf
Epoch: 0002 train loss= 2958.218994 test loss= inf
Saved:  _models/sweep/w-200_d-2_e-34_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 2834.057617 test loss= inf
Epoch: 0002 train loss= 2708.645508 test loss= inf
Saved:  _models/sweep/w-200_d-2_e-36_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 2581.912842 test loss= inf
Epoch: 0002 train loss= 2453.677246 test loss= inf
Saved:  _models/sweep/w-200_d-2_e-38_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 2323.959473 test loss= inf
Epoch: 0002 train loss= 2193.662109 test loss= inf
Saved:  _models/sweep/w-200_d-2_e-40_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 2062.460938 test loss= 147.493606
Epoch: 0002 train loss= 1931.592896 test loss= 149.915999
------------------------------Completed Depth=2	Width= 200 !------------------------------
------------------------------Running Depth= 3 	Width= 200 ------------------------------
Epoch: 0001 train loss= 15296.593750 test loss= 1989.104840
Epoch: 0002 train loss= 15004.982422 test loss= 1792.184273
Saved:  _models/sweep/w-200_d-3_e-2_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 14702.179688 test loss= 1602.108137
Epoch: 0002 train loss= 14386.769531 test loss= 1425.262458
Saved:  _models/sweep/w-200_d-3_e-4_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 14048.383789 test loss= 1257.707197
Epoch: 0002 train loss= 13693.261719 test loss= 1095.115516
Saved:  _models/sweep/w-200_d-3_e-6_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 13311.841797 test loss= 942.121174
Epoch: 0002 train loss= 12908.990234 test loss= 813.191231
Saved:  _models/sweep/w-200_d-3_e-8_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 12477.810547 test loss= 705.475176
Epoch: 0002 train loss= 12022.387695 test loss= 615.534401
Saved:  _models/sweep/w-200_d-3_e-10_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 11542.143555 test loss= 543.800982
Epoch: 0002 train loss= 11034.806641 test loss= 482.745348
Saved:  _models/sweep/w-200_d-3_e-12_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 10497.920898 test loss= 431.340157
Epoch: 0002 train loss= 9947.179688 test loss= 388.314392
Saved:  _models/sweep/w-200_d-3_e-14_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 9383.951172 test loss= 351.120334
Epoch: 0002 train loss= 8813.783203 test loss= 318.769723
Saved:  _models/sweep/w-200_d-3_e-16_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 8243.779297 test loss= 289.888399
Epoch: 0002 train loss= 7683.307617 test loss= 264.424312
Saved:  _models/sweep/w-200_d-3_e-18_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 7141.000000 test loss= 241.403313
Epoch: 0002 train loss= 6632.003906 test loss= 221.680628
Saved:  _models/sweep/w-200_d-3_e-20_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 6160.707031 test loss= 204.319953
Epoch: 0002 train loss= 5738.513672 test loss= inf
------------------------------Completed Depth=3	Width= 200 !------------------------------
------------------------------Running Depth= 4 	Width= 200 ------------------------------
Epoch: 0001 train loss= 15644.239258 test loss= 1363.004833
Epoch: 0002 train loss= 15461.637695 test loss= 1291.706293
Saved:  _models/sweep/w-200_d-4_e-2_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 15276.860352 test loss= 1219.192889
Epoch: 0002 train loss= 15086.791016 test loss= 1143.065615
Saved:  _models/sweep/w-200_d-4_e-4_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 14885.411133 test loss= 1065.537050
Epoch: 0002 train loss= 14659.689453 test loss= 980.660333
Saved:  _models/sweep/w-200_d-4_e-6_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 14405.087891 test loss= 899.230150
Epoch: 0002 train loss= 14113.731445 test loss= 816.887526
Saved:  _models/sweep/w-200_d-4_e-8_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 13778.804688 test loss= 741.863810
Epoch: 0002 train loss= 13394.740234 test loss= 671.844099
Saved:  _models/sweep/w-200_d-4_e-10_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 12959.925781 test loss= 611.700240
Epoch: 0002 train loss= 12471.458984 test loss= 555.474284
Saved:  _models/sweep/w-200_d-4_e-12_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 11926.426758 test loss= 506.145143
Epoch: 0002 train loss= 11325.229492 test loss= 459.727177
Saved:  _models/sweep/w-200_d-4_e-14_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 10667.734375 test loss= 417.647289
Epoch: 0002 train loss= 9976.727539 test loss= 378.122613
Saved:  _models/sweep/w-200_d-4_e-16_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 9261.929688 test loss= 341.681442
Epoch: 0002 train loss= 8531.142578 test loss= 307.453235
Saved:  _models/sweep/w-200_d-4_e-18_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 7797.020996 test loss= 275.768549
Epoch: 0002 train loss= 7107.097168 test loss= 248.649619
Saved:  _models/sweep/w-200_d-4_e-20_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 6469.081543 test loss= inf
Epoch: 0002 train loss= 5918.860352 test loss= inf
Saved:  _models/sweep/w-200_d-4_e-22_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 5462.969238 test loss= inf
Epoch: 0002 train loss= 5122.265137 test loss= inf
Saved:  _models/sweep/w-200_d-4_e-24_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 4885.735352 test loss= inf
Epoch: 0002 train loss= 4738.743652 test loss= inf
Saved:  _models/sweep/w-200_d-4_e-26_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 4643.305664 test loss= inf
Epoch: 0002 train loss= 4563.972168 test loss= inf
Saved:  _models/sweep/w-200_d-4_e-28_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 4486.439453 test loss= inf
Epoch: 0002 train loss= 4406.559570 test loss= inf
Saved:  _models/sweep/w-200_d-4_e-30_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 4324.324707 test loss= inf
Epoch: 0002 train loss= 4241.175781 test loss= inf
Saved:  _models/sweep/w-200_d-4_e-32_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 4157.994629 test loss= inf
Epoch: 0002 train loss= 4075.476562 test loss= inf
Saved:  _models/sweep/w-200_d-4_e-34_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 3992.782959 test loss= inf
Epoch: 0002 train loss= 3909.347168 test loss= inf
Saved:  _models/sweep/w-200_d-4_e-36_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 3823.312256 test loss= inf
Epoch: 0002 train loss= 3733.698975 test loss= inf
Saved:  _models/sweep/w-200_d-4_e-38_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 3638.805664 test loss= inf
Epoch: 0002 train loss= 3538.020752 test loss= inf
Saved:  _models/sweep/w-200_d-4_e-40_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 3431.118408 test loss= inf
Epoch: 0002 train loss= 3318.614746 test loss= inf
Saved:  _models/sweep/w-200_d-4_e-42_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 3199.985352 test loss= inf
Epoch: 0002 train loss= 3077.065918 test loss= inf
Saved:  _models/sweep/w-200_d-4_e-44_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 2951.261719 test loss= inf
Epoch: 0002 train loss= 2823.713623 test loss= inf
Saved:  _models/sweep/w-200_d-4_e-46_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 2696.904785 test loss= inf
Epoch: 0002 train loss= 2573.117432 test loss= inf
Saved:  _models/sweep/w-200_d-4_e-48_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 2451.581543 test loss= inf
Epoch: 0002 train loss= 2334.266602 test loss= inf
Saved:  _models/sweep/w-200_d-4_e-50_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 2220.046631 test loss= 151.258693
Epoch: 0002 train loss= 2109.166748 test loss= 158.879688
------------------------------Completed Depth=4	Width= 200 !------------------------------
------------------------------Running Depth= 1 	Width= 250 ------------------------------
Epoch: 0001 train loss= 14048.476562 test loss= 1110.860636
Epoch: 0002 train loss= 13161.269531 test loss= 822.101881
Saved:  _models/sweep/w-250_d-1_e-2_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 12327.868164 test loss= 653.502992
Epoch: 0002 train loss= 11551.045898 test loss= 555.007791
Saved:  _models/sweep/w-250_d-1_e-4_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 10812.762695 test loss= 485.898686
Epoch: 0002 train loss= 10125.642578 test loss= 437.374780
Saved:  _models/sweep/w-250_d-1_e-6_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 9475.091797 test loss= 398.070387
Epoch: 0002 train loss= 8868.272461 test loss= 366.755524
Saved:  _models/sweep/w-250_d-1_e-8_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 8293.620117 test loss= 339.291974
Epoch: 0002 train loss= 7757.415039 test loss= 316.191874
Saved:  _models/sweep/w-250_d-1_e-10_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 7255.869141 test loss= 295.362164
Epoch: 0002 train loss= 6787.496094 test loss= 277.306594
Saved:  _models/sweep/w-250_d-1_e-12_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 6346.350586 test loss= 260.410051
Epoch: 0002 train loss= 5939.851074 test loss= 246.054411
Saved:  _models/sweep/w-250_d-1_e-14_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 5560.685059 test loss= 232.660944
Epoch: 0002 train loss= 5212.630371 test loss= 220.972160
Saved:  _models/sweep/w-250_d-1_e-16_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 4890.438965 test loss= 210.141766
Epoch: 0002 train loss= 4596.124512 test loss= 200.713878
Saved:  _models/sweep/w-250_d-1_e-18_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 4326.083984 test loss= 192.006298
Epoch: 0002 train loss= 4080.442139 test loss= 184.426909
Saved:  _models/sweep/w-250_d-1_e-20_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 3854.661621 test loss= 177.127182
Epoch: 0002 train loss= 3649.907471 test loss= 171.093217
Saved:  _models/sweep/w-250_d-1_e-22_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 3463.677979 test loss= 165.516863
Epoch: 0002 train loss= 3291.961670 test loss= 160.602221
Saved:  _models/sweep/w-250_d-1_e-24_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 3131.346436 test loss= 155.684442
Epoch: 0002 train loss= 2980.638672 test loss= 151.507166
Saved:  _models/sweep/w-250_d-1_e-26_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 2837.145264 test loss= 147.636868
Epoch: 0002 train loss= 2699.672607 test loss= 144.132209
Saved:  _models/sweep/w-250_d-1_e-28_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 2566.401123 test loss= 141.042408
Epoch: 0002 train loss= 2436.099121 test loss= 138.166167
Saved:  _models/sweep/w-250_d-1_e-30_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 2307.809326 test loss= 135.873527
Epoch: 0002 train loss= 2181.262451 test loss= 134.002387
Saved:  _models/sweep/w-250_d-1_e-32_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 2055.678467 test loss= 133.597282
Epoch: 0002 train loss= 1931.391968 test loss= 135.082490
------------------------------Completed Depth=1	Width= 250 !------------------------------
------------------------------Running Depth= 2 	Width= 250 ------------------------------
Epoch: 0001 train loss= 15557.293945 test loss= 1291.129259
Epoch: 0002 train loss= 14860.362305 test loss= 983.978082
Saved:  _models/sweep/w-250_d-2_e-2_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 14188.677734 test loss= 810.591998
Epoch: 0002 train loss= 13532.697266 test loss= 703.709613
Saved:  _models/sweep/w-250_d-2_e-4_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 12879.729492 test loss= 633.201056
Epoch: 0002 train loss= 12230.988281 test loss= 583.173031
Saved:  _models/sweep/w-250_d-2_e-6_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 11584.490234 test loss= 543.873853
Epoch: 0002 train loss= 10935.503906 test loss= 509.332980
Saved:  _models/sweep/w-250_d-2_e-8_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 10282.675781 test loss= 478.041337
Epoch: 0002 train loss= 9632.508789 test loss= 447.943909
Saved:  _models/sweep/w-250_d-2_e-10_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 8981.909180 test loss= 419.186868
Epoch: 0002 train loss= 8344.933594 test loss= 391.018215
Saved:  _models/sweep/w-250_d-2_e-12_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 7721.020020 test loss= 364.155244
Epoch: 0002 train loss= 7124.616211 test loss= 338.604877
Saved:  _models/sweep/w-250_d-2_e-14_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 6554.161621 test loss= 313.697672
Epoch: 0002 train loss= 6029.801270 test loss= 292.082945
Saved:  _models/sweep/w-250_d-2_e-16_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 5550.947754 test loss= inf
Epoch: 0002 train loss= 5124.155273 test loss= inf
Saved:  _models/sweep/w-250_d-2_e-18_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 4745.042480 test loss= inf
Epoch: 0002 train loss= 4418.029785 test loss= inf
Saved:  _models/sweep/w-250_d-2_e-20_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 4135.594238 test loss= inf
Epoch: 0002 train loss= 3896.385986 test loss= inf
Saved:  _models/sweep/w-250_d-2_e-22_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 3690.725830 test loss= inf
Epoch: 0002 train loss= 3509.977295 test loss= inf
Saved:  _models/sweep/w-250_d-2_e-24_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 3343.451172 test loss= inf
Epoch: 0002 train loss= 3183.471436 test loss= inf
Saved:  _models/sweep/w-250_d-2_e-26_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 3025.309570 test loss= inf
Epoch: 0002 train loss= 2866.228027 test loss= inf
Saved:  _models/sweep/w-250_d-2_e-28_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 2706.068604 test loss= inf
Epoch: 0002 train loss= 2545.012207 test loss= inf
Saved:  _models/sweep/w-250_d-2_e-30_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 2381.364014 test loss= inf
Epoch: 0002 train loss= 2216.192627 test loss= inf
Saved:  _models/sweep/w-250_d-2_e-32_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 2049.314209 test loss= inf
Epoch: 0002 train loss= 1881.217285 test loss= 118.462696
Saved:  _models/sweep/w-250_d-2_e-34_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 1711.837280 test loss= 114.092641
Epoch: 0002 train loss= 1541.821533 test loss= 110.055934
Saved:  _models/sweep/w-250_d-2_e-36_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 1370.831787 test loss= 108.981374
Epoch: 0002 train loss= 1200.022461 test loss= 116.743730
------------------------------Completed Depth=2	Width= 250 !------------------------------
------------------------------Running Depth= 3 	Width= 250 ------------------------------
Epoch: 0001 train loss= 15413.505859 test loss= 1235.735138
Epoch: 0002 train loss= 14963.764648 test loss= 1051.387817
Saved:  _models/sweep/w-250_d-3_e-2_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 14510.163086 test loss= 906.562575
Epoch: 0002 train loss= 14045.979492 test loss= 787.963723
Saved:  _models/sweep/w-250_d-3_e-4_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 13556.836914 test loss= 699.270940
Epoch: 0002 train loss= 13030.883789 test loss= 626.614042
Saved:  _models/sweep/w-250_d-3_e-6_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 12461.286133 test loss= 571.167327
Epoch: 0002 train loss= 11848.820312 test loss= 524.054834
Saved:  _models/sweep/w-250_d-3_e-8_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 11191.697266 test loss= 484.649487
Epoch: 0002 train loss= 10501.972656 test loss= 448.480303
Saved:  _models/sweep/w-250_d-3_e-10_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 9779.406250 test loss= 415.149064
Epoch: 0002 train loss= 9051.203125 test loss= 384.618413
Saved:  _models/sweep/w-250_d-3_e-12_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 8317.983398 test loss= 355.893018
Epoch: 0002 train loss= 7610.362305 test loss= 330.385903
Saved:  _models/sweep/w-250_d-3_e-14_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 6930.717773 test loss= 307.365327
Epoch: 0002 train loss= 6305.829590 test loss= inf
------------------------------Completed Depth=3	Width= 250 !------------------------------
------------------------------Running Depth= 4 	Width= 250 ------------------------------
Epoch: 0001 train loss= 15000.929688 test loss= 1404.280461
Epoch: 0002 train loss= 14709.491211 test loss= 1274.801178
Saved:  _models/sweep/w-250_d-4_e-2_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 14389.189453 test loss= 1137.152070
Epoch: 0002 train loss= 14036.326172 test loss= 991.599391
Saved:  _models/sweep/w-250_d-4_e-4_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 13633.558594 test loss= 856.258019
Epoch: 0002 train loss= 13157.036133 test loss= 724.999013
Saved:  _models/sweep/w-250_d-4_e-6_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 12605.716797 test loss= 622.310433
Epoch: 0002 train loss= 11974.086914 test loss= 533.330596
Saved:  _models/sweep/w-250_d-4_e-8_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 11255.016602 test loss= 462.607948
Epoch: 0002 train loss= 10452.271484 test loss= 401.165514
Saved:  _models/sweep/w-250_d-4_e-10_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 9586.023438 test loss= 349.684453
Epoch: 0002 train loss= 8691.621094 test loss= 304.582697
Saved:  _models/sweep/w-250_d-4_e-12_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 7799.645020 test loss= 265.959813
Epoch: 0002 train loss= 6976.188965 test loss= 235.084461
Saved:  _models/sweep/w-250_d-4_e-14_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 6241.226562 test loss= inf
Epoch: 0002 train loss= 5652.562988 test loss= inf
Saved:  _models/sweep/w-250_d-4_e-16_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 5212.718262 test loss= inf
Epoch: 0002 train loss= 4939.714844 test loss= inf
Saved:  _models/sweep/w-250_d-4_e-18_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 4787.272949 test loss= inf
Epoch: 0002 train loss= 4692.841309 test loss= inf
Saved:  _models/sweep/w-250_d-4_e-20_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 4608.799316 test loss= inf
Epoch: 0002 train loss= 4520.574707 test loss= inf
Saved:  _models/sweep/w-250_d-4_e-22_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 4427.357422 test loss= inf
Epoch: 0002 train loss= 4329.741699 test loss= inf
Saved:  _models/sweep/w-250_d-4_e-24_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 4229.009766 test loss= inf
Epoch: 0002 train loss= 4125.550293 test loss= inf
Saved:  _models/sweep/w-250_d-4_e-26_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 4018.547363 test loss= inf
Epoch: 0002 train loss= 3905.301025 test loss= inf
Saved:  _models/sweep/w-250_d-4_e-28_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 3782.792480 test loss= inf
Epoch: 0002 train loss= 3651.052979 test loss= inf
Saved:  _models/sweep/w-250_d-4_e-30_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 3507.271729 test loss= inf
Epoch: 0002 train loss= 3349.334229 test loss= inf
Saved:  _models/sweep/w-250_d-4_e-32_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 3177.183350 test loss= inf
Epoch: 0002 train loss= 2990.913086 test loss= inf
Saved:  _models/sweep/w-250_d-4_e-34_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 2789.400879 test loss= inf
Epoch: 0002 train loss= 2572.788330 test loss= inf
Saved:  _models/sweep/w-250_d-4_e-36_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 2343.939209 test loss= inf
Epoch: 0002 train loss= 2108.061279 test loss= inf
Saved:  _models/sweep/w-250_d-4_e-38_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 1867.973389 test loss= inf
Epoch: 0002 train loss= 1628.675903 test loss= 127.106180
Saved:  _models/sweep/w-250_d-4_e-40_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 1392.313721 test loss= 123.959195
Epoch: 0002 train loss= 1162.013794 test loss= 123.275953
Saved:  _models/sweep/w-250_d-4_e-42_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 937.529053 test loss= 146.147172
Epoch: 0002 train loss= 723.592285 test loss= 1241.930356
------------------------------Completed Depth=4	Width= 250 !------------------------------
------------------------------Running Depth= 1 	Width= 300 ------------------------------
Epoch: 0001 train loss= 15949.977539 test loss= 94301.529080
Epoch: 0002 train loss= 14698.679688 test loss= 26449.058588
Saved:  _models/sweep/w-300_d-1_e-2_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 13557.297852 test loss= 7313.782766
Epoch: 0002 train loss= 12509.099609 test loss= 2227.090756
Saved:  _models/sweep/w-300_d-1_e-4_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 11536.002930 test loss= 883.627099
Epoch: 0002 train loss= 10634.356445 test loss= 541.606071
Saved:  _models/sweep/w-300_d-1_e-6_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 9790.389648 test loss= 418.421375
Epoch: 0002 train loss= 9016.470703 test loss= 363.624667
Saved:  _models/sweep/w-300_d-1_e-8_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 8302.140625 test loss= 326.285585
Epoch: 0002 train loss= 7641.653320 test loss= 298.085570
Saved:  _models/sweep/w-300_d-1_e-10_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 7026.935059 test loss= 273.260847
Epoch: 0002 train loss= 6463.429199 test loss= 252.455859
Saved:  _models/sweep/w-300_d-1_e-12_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 5942.670898 test loss= 233.218360
Epoch: 0002 train loss= 5467.896484 test loss= 216.814203
Saved:  _models/sweep/w-300_d-1_e-14_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 5035.401367 test loss= 201.993036
Epoch: 0002 train loss= 4642.688965 test loss= 188.960278
Saved:  _models/sweep/w-300_d-1_e-16_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 4285.860352 test loss= 177.107022
Epoch: 0002 train loss= 3966.186523 test loss= inf
------------------------------Completed Depth=1	Width= 300 !------------------------------
------------------------------Running Depth= 2 	Width= 300 ------------------------------
Epoch: 0001 train loss= 14973.483398 test loss= 1248.988784
Epoch: 0002 train loss= 14147.681641 test loss= 995.603655
Saved:  _models/sweep/w-300_d-2_e-2_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 13327.849609 test loss= 811.180601
Epoch: 0002 train loss= 12516.893555 test loss= 675.096223
Saved:  _models/sweep/w-300_d-2_e-4_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 11702.144531 test loss= 575.691657
Epoch: 0002 train loss= 10896.017578 test loss= 502.851136
Saved:  _models/sweep/w-300_d-2_e-6_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 10085.278320 test loss= 445.431817
Epoch: 0002 train loss= 9290.621094 test loss= 399.997803
Saved:  _models/sweep/w-300_d-2_e-8_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 8514.896484 test loss= 361.218458
Epoch: 0002 train loss= 7762.347656 test loss= 328.096682
Saved:  _models/sweep/w-300_d-2_e-10_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 7037.145020 test loss= 298.712014
Epoch: 0002 train loss= 6360.779785 test loss= 273.849653
Saved:  _models/sweep/w-300_d-2_e-12_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 5734.520508 test loss= 251.724164
Epoch: 0002 train loss= 5173.330078 test loss= 233.865426
Saved:  _models/sweep/w-300_d-2_e-14_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 4672.915039 test loss= 217.170688
Epoch: 0002 train loss= 4243.744629 test loss= 204.156424
Saved:  _models/sweep/w-300_d-2_e-16_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 3875.950684 test loss= inf
Epoch: 0002 train loss= 3570.782227 test loss= inf
Saved:  _models/sweep/w-300_d-2_e-18_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 3311.716797 test loss= inf
Epoch: 0002 train loss= 3083.636475 test loss= inf
Saved:  _models/sweep/w-300_d-2_e-20_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 2870.898193 test loss= inf
Epoch: 0002 train loss= 2663.264160 test loss= inf
Saved:  _models/sweep/w-300_d-2_e-22_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 2457.098877 test loss= inf
Epoch: 0002 train loss= 2251.968018 test loss= inf
Saved:  _models/sweep/w-300_d-2_e-24_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 2048.634033 test loss= 167.967730
Epoch: 0002 train loss= 1848.335938 test loss= 194.676886
------------------------------Completed Depth=2	Width= 300 !------------------------------
------------------------------Running Depth= 3 	Width= 300 ------------------------------
Epoch: 0001 train loss= 15434.520508 test loss= 1048.962623
Epoch: 0002 train loss= 14943.674805 test loss= 885.955767
Saved:  _models/sweep/w-300_d-3_e-2_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 14441.285156 test loss= 759.408220
Epoch: 0002 train loss= 13911.840820 test loss= 660.387151
Saved:  _models/sweep/w-300_d-3_e-4_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 13332.320312 test loss= 584.241548
Epoch: 0002 train loss= 12690.053711 test loss= 519.807640
Saved:  _models/sweep/w-300_d-3_e-6_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 11974.708008 test loss= 467.278582
Epoch: 0002 train loss= 11194.767578 test loss= 419.234997
Saved:  _models/sweep/w-300_d-3_e-8_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 10350.453125 test loss= 375.979283
Epoch: 0002 train loss= 9469.032227 test loss= 335.927714
Saved:  _models/sweep/w-300_d-3_e-10_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 8565.438477 test loss= 299.217695
Epoch: 0002 train loss= 7677.687500 test loss= 266.548591
Saved:  _models/sweep/w-300_d-3_e-12_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 6825.331055 test loss= 237.647690
Epoch: 0002 train loss= 6050.533203 test loss= inf
------------------------------Completed Depth=3	Width= 300 !------------------------------
------------------------------Running Depth= 4 	Width= 300 ------------------------------
Epoch: 0001 train loss= 15148.968750 test loss= 1356.037047
Epoch: 0002 train loss= 14870.761719 test loss= 1239.835298
Saved:  _models/sweep/w-300_d-4_e-2_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 14561.659180 test loss= 1116.767566
Epoch: 0002 train loss= 14207.712891 test loss= 976.210840
Saved:  _models/sweep/w-300_d-4_e-4_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 13787.349609 test loss= 835.924102
Epoch: 0002 train loss= 13278.791992 test loss= 692.808457
Saved:  _models/sweep/w-300_d-4_e-6_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 12653.070312 test loss= 580.245595
Epoch: 0002 train loss= 11903.907227 test loss= 483.185386
Saved:  _models/sweep/w-300_d-4_e-8_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 11029.272461 test loss= 409.420025
Epoch: 0002 train loss= 10044.637695 test loss= 344.386534
Saved:  _models/sweep/w-300_d-4_e-10_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 8978.000977 test loss= 290.740223
Epoch: 0002 train loss= 7920.065430 test loss= 246.932433
Saved:  _models/sweep/w-300_d-4_e-12_lr-5e-07_b-64_ds-pink_p-True
Epoch: 0001 train loss= 6922.479492 test loss= 211.427570
Epoch: 0002 train loss= 6074.151855 test loss= inf
------------------------------Completed Depth=4	Width= 300 !------------------------------
Pink Sweep Complete!
------------------------------Running Depth= 1 	Width= 50 ------------------------------
Epoch: 0001 train loss= 39632.847656 test loss= 418.910525
Epoch: 0002 train loss= 39105.925781 test loss= 416.522179
Saved:  _models/sweep/w-50_d-1_e-2_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 38496.039062 test loss= 413.422112
Epoch: 0002 train loss= 38003.386719 test loss= 411.081031
Saved:  _models/sweep/w-50_d-1_e-4_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 37465.722656 test loss= 408.105070
Epoch: 0002 train loss= 36991.199219 test loss= 405.659466
Saved:  _models/sweep/w-50_d-1_e-6_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 36451.835938 test loss= 402.936810
Epoch: 0002 train loss= 35995.343750 test loss= 400.486239
Saved:  _models/sweep/w-50_d-1_e-8_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 35499.054688 test loss= 397.740349
Epoch: 0002 train loss= 35065.167969 test loss= 395.402960
Saved:  _models/sweep/w-50_d-1_e-10_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 34531.367188 test loss= 392.552582
Epoch: 0002 train loss= 34089.671875 test loss= 390.179643
Saved:  _models/sweep/w-50_d-1_e-12_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 33613.523438 test loss= 387.123520
Epoch: 0002 train loss= 33180.093750 test loss= 384.809855
Saved:  _models/sweep/w-50_d-1_e-14_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 32712.390625 test loss= 382.103309
Epoch: 0002 train loss= 32310.773438 test loss= 379.672457
Saved:  _models/sweep/w-50_d-1_e-16_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 31854.544922 test loss= 376.872485
Epoch: 0002 train loss= 31460.882812 test loss= 374.420234
Saved:  _models/sweep/w-50_d-1_e-18_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 31020.632812 test loss= 371.692510
Epoch: 0002 train loss= 30635.607422 test loss= 369.279340
Saved:  _models/sweep/w-50_d-1_e-20_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 30235.734375 test loss= 366.765813
Epoch: 0002 train loss= 29848.568359 test loss= 364.186280
Saved:  _models/sweep/w-50_d-1_e-22_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 29357.800781 test loss= 360.919383
Epoch: 0002 train loss= 28964.710938 test loss= 358.521482
Saved:  _models/sweep/w-50_d-1_e-24_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 28539.806641 test loss= 355.818359
Epoch: 0002 train loss= 28175.921875 test loss= 353.447671
Saved:  _models/sweep/w-50_d-1_e-26_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 27796.009766 test loss= 350.783696
Epoch: 0002 train loss= 27449.251953 test loss= 348.393534
Saved:  _models/sweep/w-50_d-1_e-28_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 27098.527344 test loss= 346.005754
Epoch: 0002 train loss= 26771.966797 test loss= 343.676323
Saved:  _models/sweep/w-50_d-1_e-30_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 26402.625000 test loss= 341.225714
Epoch: 0002 train loss= 26072.351562 test loss= 338.885387
Saved:  _models/sweep/w-50_d-1_e-32_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 25712.722656 test loss= 336.401740
Epoch: 0002 train loss= 25390.833984 test loss= 334.065855
Saved:  _models/sweep/w-50_d-1_e-34_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 25022.431641 test loss= 331.455236
Epoch: 0002 train loss= 24701.251953 test loss= 329.182681
Saved:  _models/sweep/w-50_d-1_e-36_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 24406.406250 test loss= 327.021722
Epoch: 0002 train loss= 24099.804688 test loss= 324.638437
Saved:  _models/sweep/w-50_d-1_e-38_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 23761.537109 test loss= 322.138685
Epoch: 0002 train loss= 23463.726562 test loss= 319.870361
Saved:  _models/sweep/w-50_d-1_e-40_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 23140.826172 test loss= 317.281555
Epoch: 0002 train loss= 22851.115234 test loss= 315.058209
Saved:  _models/sweep/w-50_d-1_e-42_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 22521.000000 test loss= 312.356086
Epoch: 0002 train loss= 22235.615234 test loss= 310.193515
Saved:  _models/sweep/w-50_d-1_e-44_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 21928.544922 test loss= 307.573191
Epoch: 0002 train loss= 21636.880859 test loss= 305.230659
Saved:  _models/sweep/w-50_d-1_e-46_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 21344.763672 test loss= 302.765293
Epoch: 0002 train loss= 21064.128906 test loss= 300.426307
Saved:  _models/sweep/w-50_d-1_e-48_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 20763.570312 test loss= 297.949620
Epoch: 0002 train loss= 20493.507812 test loss= 295.634445
Saved:  _models/sweep/w-50_d-1_e-50_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 20195.240234 test loss= 292.987020
Epoch: 0002 train loss= 19920.960938 test loss= 290.643295
Saved:  _models/sweep/w-50_d-1_e-52_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 19641.105469 test loss= 288.225974
Epoch: 0002 train loss= 19372.050781 test loss= 285.826859
Saved:  _models/sweep/w-50_d-1_e-54_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 19095.552734 test loss= 283.239156
Epoch: 0002 train loss= 18835.611328 test loss= 280.918147
Saved:  _models/sweep/w-50_d-1_e-56_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 18546.332031 test loss= 278.271489
Epoch: 0002 train loss= 18288.548828 test loss= 275.940267
Saved:  _models/sweep/w-50_d-1_e-58_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 17993.392578 test loss= 273.138666
Epoch: 0002 train loss= 17731.820312 test loss= 270.704708
Saved:  _models/sweep/w-50_d-1_e-60_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 17485.318359 test loss= 268.362329
Epoch: 0002 train loss= 17233.902344 test loss= 265.920371
Saved:  _models/sweep/w-50_d-1_e-62_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 16981.865234 test loss= 263.397279
Epoch: 0002 train loss= 16732.841797 test loss= 260.921756
Saved:  _models/sweep/w-50_d-1_e-64_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 16474.736328 test loss= 258.336959
Epoch: 0002 train loss= 16228.044922 test loss= 255.811858
Saved:  _models/sweep/w-50_d-1_e-66_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 15980.494141 test loss= 253.239204
Epoch: 0002 train loss= 15738.459961 test loss= 250.718669
Saved:  _models/sweep/w-50_d-1_e-68_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 15497.117188 test loss= 248.103188
Epoch: 0002 train loss= 15263.742188 test loss= 245.632571
Saved:  _models/sweep/w-50_d-1_e-70_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 15029.702148 test loss= 243.059806
Epoch: 0002 train loss= 14796.774414 test loss= 240.500477
Saved:  _models/sweep/w-50_d-1_e-72_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 14536.197266 test loss= 237.462810
Epoch: 0002 train loss= 14300.750977 test loss= 234.964286
Saved:  _models/sweep/w-50_d-1_e-74_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 14062.748047 test loss= 232.220031
Epoch: 0002 train loss= 13836.333008 test loss= 229.629572
Saved:  _models/sweep/w-50_d-1_e-76_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 13611.783203 test loss= 227.018313
Epoch: 0002 train loss= 13392.745117 test loss= 224.397055
Saved:  _models/sweep/w-50_d-1_e-78_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 13161.591797 test loss= 221.616961
Epoch: 0002 train loss= 12945.571289 test loss= 219.042646
Saved:  _models/sweep/w-50_d-1_e-80_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 12725.307617 test loss= 216.243741
Epoch: 0002 train loss= 12511.488281 test loss= 213.611907
Saved:  _models/sweep/w-50_d-1_e-82_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 12302.386719 test loss= 210.988468
Epoch: 0002 train loss= 12092.845703 test loss= 208.280325
Saved:  _models/sweep/w-50_d-1_e-84_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 11876.533203 test loss= 205.470421
Epoch: 0002 train loss= 11668.775391 test loss= 202.757343
Saved:  _models/sweep/w-50_d-1_e-86_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 11455.659180 test loss= 199.930163
Epoch: 0002 train loss= 11253.811523 test loss= 197.247616
Saved:  _models/sweep/w-50_d-1_e-88_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 11051.143555 test loss= 194.525022
Epoch: 0002 train loss= 10855.557617 test loss= 191.822576
Saved:  _models/sweep/w-50_d-1_e-90_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 10645.008789 test loss= 188.785224
Epoch: 0002 train loss= 10451.823242 test loss= 186.177585
Saved:  _models/sweep/w-50_d-1_e-92_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 10261.390625 test loss= 183.450767
Epoch: 0002 train loss= 10074.099609 test loss= 180.739931
Saved:  _models/sweep/w-50_d-1_e-94_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 9887.267578 test loss= 178.020837
Epoch: 0002 train loss= 9704.586914 test loss= 175.348607
Saved:  _models/sweep/w-50_d-1_e-96_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 9520.463867 test loss= 172.590084
Epoch: 0002 train loss= 9344.416992 test loss= 169.935508
Saved:  _models/sweep/w-50_d-1_e-98_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 9167.027344 test loss= 167.228772
Epoch: 0002 train loss= 8997.320312 test loss= 164.623669
Saved:  _models/sweep/w-50_d-1_e-100_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 8826.543945 test loss= 161.940708
Epoch: 0002 train loss= 8663.723633 test loss= 159.413504
Saved:  _models/sweep/w-50_d-1_e-102_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 8504.611328 test loss= 156.881628
Epoch: 0002 train loss= 8344.981445 test loss= 154.296486
Saved:  _models/sweep/w-50_d-1_e-104_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 8180.557129 test loss= 151.593896
Epoch: 0002 train loss= 8027.752441 test loss= 149.099704
Saved:  _models/sweep/w-50_d-1_e-106_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 7874.196777 test loss= 146.485846
Epoch: 0002 train loss= 7726.736328 test loss= 144.052622
Saved:  _models/sweep/w-50_d-1_e-108_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 7584.048828 test loss= 141.623943
Epoch: 0002 train loss= 7445.400879 test loss= 139.260632
Saved:  _models/sweep/w-50_d-1_e-110_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 7304.258789 test loss= 136.815966
Epoch: 0002 train loss= 7171.003418 test loss= 134.508954
Saved:  _models/sweep/w-50_d-1_e-112_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 7040.135742 test loss= 132.179574
Epoch: 0002 train loss= 6913.962402 test loss= 129.954494
Saved:  _models/sweep/w-50_d-1_e-114_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 6789.697754 test loss= 127.727873
Epoch: 0002 train loss= 6670.869629 test loss= 125.589206
Saved:  _models/sweep/w-50_d-1_e-116_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 6551.750000 test loss= 123.371153
Epoch: 0002 train loss= 6438.144531 test loss= 121.304448
Saved:  _models/sweep/w-50_d-1_e-118_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 6330.255371 test loss= 119.305599
Epoch: 0002 train loss= 6224.948242 test loss= 117.343766
Saved:  _models/sweep/w-50_d-1_e-120_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 6120.011719 test loss= 115.337500
Epoch: 0002 train loss= 6019.976562 test loss= 113.453185
Saved:  _models/sweep/w-50_d-1_e-122_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 5922.638672 test loss= 111.550331
Epoch: 0002 train loss= 5829.338867 test loss= 109.783116
Saved:  _models/sweep/w-50_d-1_e-124_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 5738.137695 test loss= 107.969174
Epoch: 0002 train loss= 5650.651367 test loss= 106.268190
Saved:  _models/sweep/w-50_d-1_e-126_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 5564.614746 test loss= 104.538454
Epoch: 0002 train loss= 5483.547363 test loss= 102.939875
Saved:  _models/sweep/w-50_d-1_e-128_lr-5e-07_b-64_ds-green_p-True
Epoch: 0001 train loss= 5406.958984 test loss= 101.411978
loss is NaN
